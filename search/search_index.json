{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Library to persist Pydantic models into different storage backends following the repository pattern . Installing \u00b6 pip install repository-orm A Simple Example \u00b6 from repository_orm import Entity , load_repository class Author ( Entity ): first_name : str last_name : str country : str repo = load_repository () author = Author ( first_name = \"Brandon\" , last_name = \"Sanderson\" , country = \"US\" ) # Add entities repo . add ( author ) repo . commit () # Retrieve entities by their ID brandon = repo . get ( 0 , Author ) assert brandon == author # Search entities brandon = repo . search ({ \"first_name\" : \"Brandon\" }, Author )[ 0 ] assert brandon == author # Delete entities repo . delete ( brandon ) repo . commit () assert len ( repo . all ( Author )) == 0 # Close the connection repo . close () Repository pattern theory \u00b6 The repository pattern is an abstraction over persistent storage, allowing you to decouple the model layer from the data layer. It hides the boring details of data access by pretending that all of our data is in memory. It has the following advantages: Give a simple interface, which you control, between persistent storage and our domain model. It's easy to make a fake version of the repository for unit testing, or to swap out different storage solutions, because the model is fully decoupled from the infrastructure. Writing the domain model before thinking about persistence helps focus on the problem at hand. If we need to change our approach, we can do that in our model, without needing to worry about foreign keys or migrations until later. Our database schema is simple because we have complete control over how we map our object to tables. Speeds up and makes more clean the business logic tests. It's easy to implement. But the following disadvantages: An ORM already buys you some decoupling. Changing foreign keys might be hard, but it should be pretty easy to swap between MySQL and Postres if you ever need to. Maintaining ORM mappings by hand requires extra work and extra code. An extra layer of abstraction is introduced, and although we may hope it will reduce complexity overall, it does add complexity locally. Furthermore it adds the WTF factor for Python programmers who've never seen this pattern before. repository-orm aims to mitigate the last ones by: Supplying classes that already have the common operations for different storage solutions. Supplying test classes and fixtures so extending the provided repositories is easy. Repositories \u00b6 There are two kinds of repositories: Data repositories : Give a common interface to store the models in databases. File repositories : Give a common interface to store computer file contents. References \u00b6 As most open sourced programs, repository-orm is standing on the shoulders of giants, namely: pydantic Used for the Entities definition. DeepDiff Used to search strings in complex objects in the FakeRepository . TinyDB Used to interact with the NoSQL database in the TinyDBRepository Pypika Used to build the SQL queries in the PypikaRepository . Yoyo Used to manage the schema changes of the PypikaRepository . Pytest Testing framework, enhanced by the awesome pytest-cases library that made the parametrization of the tests a lovely experience. Mypy Python static type checker. Flakeheaven Python linter with lots of checks . Black Python formatter to keep a nice style without effort. Autoimport Python formatter to automatically fix wrong import statements. isort Python formatter to order the import statements. Pip-tools Command line tool to manage the dependencies. Mkdocs To build this documentation site, with the Material theme . Safety To check the installed dependencies for known security vulnerabilities. Bandit To finds common security issues in Python code. Yamlfix YAML fixer. Contributing \u00b6 For guidance on setting up a development environment, and how to make a contribution to repository-orm , see Contributing to repository-orm .","title":"Repository ORM"},{"location":"#installing","text":"pip install repository-orm","title":"Installing"},{"location":"#a-simple-example","text":"from repository_orm import Entity , load_repository class Author ( Entity ): first_name : str last_name : str country : str repo = load_repository () author = Author ( first_name = \"Brandon\" , last_name = \"Sanderson\" , country = \"US\" ) # Add entities repo . add ( author ) repo . commit () # Retrieve entities by their ID brandon = repo . get ( 0 , Author ) assert brandon == author # Search entities brandon = repo . search ({ \"first_name\" : \"Brandon\" }, Author )[ 0 ] assert brandon == author # Delete entities repo . delete ( brandon ) repo . commit () assert len ( repo . all ( Author )) == 0 # Close the connection repo . close ()","title":"A Simple Example"},{"location":"#repository-pattern-theory","text":"The repository pattern is an abstraction over persistent storage, allowing you to decouple the model layer from the data layer. It hides the boring details of data access by pretending that all of our data is in memory. It has the following advantages: Give a simple interface, which you control, between persistent storage and our domain model. It's easy to make a fake version of the repository for unit testing, or to swap out different storage solutions, because the model is fully decoupled from the infrastructure. Writing the domain model before thinking about persistence helps focus on the problem at hand. If we need to change our approach, we can do that in our model, without needing to worry about foreign keys or migrations until later. Our database schema is simple because we have complete control over how we map our object to tables. Speeds up and makes more clean the business logic tests. It's easy to implement. But the following disadvantages: An ORM already buys you some decoupling. Changing foreign keys might be hard, but it should be pretty easy to swap between MySQL and Postres if you ever need to. Maintaining ORM mappings by hand requires extra work and extra code. An extra layer of abstraction is introduced, and although we may hope it will reduce complexity overall, it does add complexity locally. Furthermore it adds the WTF factor for Python programmers who've never seen this pattern before. repository-orm aims to mitigate the last ones by: Supplying classes that already have the common operations for different storage solutions. Supplying test classes and fixtures so extending the provided repositories is easy.","title":"Repository pattern theory"},{"location":"#repositories","text":"There are two kinds of repositories: Data repositories : Give a common interface to store the models in databases. File repositories : Give a common interface to store computer file contents.","title":"Repositories"},{"location":"#references","text":"As most open sourced programs, repository-orm is standing on the shoulders of giants, namely: pydantic Used for the Entities definition. DeepDiff Used to search strings in complex objects in the FakeRepository . TinyDB Used to interact with the NoSQL database in the TinyDBRepository Pypika Used to build the SQL queries in the PypikaRepository . Yoyo Used to manage the schema changes of the PypikaRepository . Pytest Testing framework, enhanced by the awesome pytest-cases library that made the parametrization of the tests a lovely experience. Mypy Python static type checker. Flakeheaven Python linter with lots of checks . Black Python formatter to keep a nice style without effort. Autoimport Python formatter to automatically fix wrong import statements. isort Python formatter to order the import statements. Pip-tools Command line tool to manage the dependencies. Mkdocs To build this documentation site, with the Material theme . Safety To check the installed dependencies for known security vulnerabilities. Bandit To finds common security issues in Python code. Yamlfix YAML fixer.","title":"References"},{"location":"#contributing","text":"For guidance on setting up a development environment, and how to make a contribution to repository-orm , see Contributing to repository-orm .","title":"Contributing"},{"location":"contributing/","text":"So you've started using repository-orm and want to show your gratitude to the project, depending on your programming skills there are different ways to do so. I don't know how to program \u00b6 There are several ways you can contribute: Open an issue if you encounter any bug or to let us know if you want a new feature to be implemented. Spread the word about the program. Review the documentation and try to improve it. I know how to program in Python \u00b6 If you have some python knowledge there are some additional ways to contribute. We've ordered the issues in milestones , check the issues in the smaller one, as it's where we'll be spending most of our efforts. Try the good first issues , as they are expected to be easier to get into the project. We develop the program with TDD , so we expect any contribution to have it's associated tests. We also try to maintain an updated documentation of the project, so think if your contribution needs to update it. We know that the expected code quality is above average. Therefore it might be changeling to get the initial grasp of the project structure, know how to make the tests, update the documentation or use all the project technology stack. but please don't let this fact discourage you from contributing: If you want to develop a new feature, explain how you'd like to do it in the related issue. If you don't know how to test your code, do the pull request without the tests and we'll try to do them for you. Issues \u00b6 Questions, feature requests and bug reports are all welcome as issues. To report a security vulnerability, please see our security policy instead. To make it as simple as possible for us to help you, please include the output of the following call in your issue: python -c \"import repository_orm.version; print(repository_orm.version.version_info())\" or if you have make installed, you can use make version . Please try to always include the above unless you're unable to install repository-orm or know it's not relevant to your question or feature request. Pull Requests \u00b6 repository-orm is released regularly so you should see your improvements release in a matter of days or weeks. Note Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request. If you're looking for something to get your teeth into, check out the \"help wanted\" label on github. Development facilities \u00b6 To make contributing as easy and fast as possible, you'll want to run tests and linting locally. tl;dr : use make format to fix formatting, make to run tests and linting & make docs to build the docs. You'll need to have python 3.6, 3.7, or 3.8, virtualenv, git, and make installed. Clone your fork and go into the repository directory: git clone git@github.com:<your username>/repository-orm.git cd repository-orm Set up the virtualenv for running tests: virtualenv -p ` which python3.7 ` env source env/bin/activate Install repository-orm, dependencies and configure the pre-commits: make install Checkout a new branch and make your changes: git checkout -b my-new-feature-branch Fix formatting and imports: repository-orm uses black to enforce formatting and isort to fix imports. make format Run tests and linting: make There are more sub-commands in Makefile like test-code , test-examples , mypy or security which you might want to use, but generally make should be all you need. If you need to pass specific arguments to pytest use the ARGS variable, for example make test ARGs='-k test_markdownlint_passes' . Build documentation: If you have changed the documentation, make sure it builds the static site. Once built it will serve the documentation at localhost:8000 : make docs Commit, push, and create your pull request. Make a new release: To generate the changelog of the new changes, build the package, upload to pypi and clean the build files use make bump . We'd love you to contribute to repository-orm !","title":"Contributing"},{"location":"contributing/#i-dont-know-how-to-program","text":"There are several ways you can contribute: Open an issue if you encounter any bug or to let us know if you want a new feature to be implemented. Spread the word about the program. Review the documentation and try to improve it.","title":"I don't know how to program"},{"location":"contributing/#i-know-how-to-program-in-python","text":"If you have some python knowledge there are some additional ways to contribute. We've ordered the issues in milestones , check the issues in the smaller one, as it's where we'll be spending most of our efforts. Try the good first issues , as they are expected to be easier to get into the project. We develop the program with TDD , so we expect any contribution to have it's associated tests. We also try to maintain an updated documentation of the project, so think if your contribution needs to update it. We know that the expected code quality is above average. Therefore it might be changeling to get the initial grasp of the project structure, know how to make the tests, update the documentation or use all the project technology stack. but please don't let this fact discourage you from contributing: If you want to develop a new feature, explain how you'd like to do it in the related issue. If you don't know how to test your code, do the pull request without the tests and we'll try to do them for you.","title":"I know how to program in Python"},{"location":"contributing/#issues","text":"Questions, feature requests and bug reports are all welcome as issues. To report a security vulnerability, please see our security policy instead. To make it as simple as possible for us to help you, please include the output of the following call in your issue: python -c \"import repository_orm.version; print(repository_orm.version.version_info())\" or if you have make installed, you can use make version . Please try to always include the above unless you're unable to install repository-orm or know it's not relevant to your question or feature request.","title":"Issues"},{"location":"contributing/#pull-requests","text":"repository-orm is released regularly so you should see your improvements release in a matter of days or weeks. Note Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request. If you're looking for something to get your teeth into, check out the \"help wanted\" label on github.","title":"Pull Requests"},{"location":"contributing/#development-facilities","text":"To make contributing as easy and fast as possible, you'll want to run tests and linting locally. tl;dr : use make format to fix formatting, make to run tests and linting & make docs to build the docs. You'll need to have python 3.6, 3.7, or 3.8, virtualenv, git, and make installed. Clone your fork and go into the repository directory: git clone git@github.com:<your username>/repository-orm.git cd repository-orm Set up the virtualenv for running tests: virtualenv -p ` which python3.7 ` env source env/bin/activate Install repository-orm, dependencies and configure the pre-commits: make install Checkout a new branch and make your changes: git checkout -b my-new-feature-branch Fix formatting and imports: repository-orm uses black to enforce formatting and isort to fix imports. make format Run tests and linting: make There are more sub-commands in Makefile like test-code , test-examples , mypy or security which you might want to use, but generally make should be all you need. If you need to pass specific arguments to pytest use the ARGS variable, for example make test ARGs='-k test_markdownlint_passes' . Build documentation: If you have changed the documentation, make sure it builds the static site. Once built it will serve the documentation at localhost:8000 : make docs Commit, push, and create your pull request. Make a new release: To generate the changelog of the new changes, build the package, upload to pypi and clean the build files use make bump . We'd love you to contribute to repository-orm !","title":"Development facilities"},{"location":"fake_repository/","text":"The FakeRepository is the simplest implementation of the repository pattern, meant to be used for the tests and early phases of development. It stores the persisted Entities in the entities object attribute in a dictionary where the keys are the Entity class and the values are list of that Entity objects. When you try to make changes to the repository, the actual entities dictionary is copied to the new_entities attribute. The changes are made on that new attribute and once you use the commit method, they get copied back to the entities attribute. Load it with: from repository_orm import load_repository repo = load_repository () Features \u00b6 Follow the overview example to see how to use each method. add Appends the Entity object to the new_entities attribute. delete Deletes the Entity object from the new_entities attribute. get Obtain an Entity from the entities attribute by it's ID. commit Persist the changes of new_entities into entities , clearing up new_entities afterwards. all Obtain all the entities of type Entity from the entities attribute. search Obtain the entities whose attributes match one or multiple conditions. We use DeepDiff's grep to search for the entities that have the value we're searching for and then we search if the key of those entities match the one we're searching for. apply_migrations Run the migrations of the repository schema. As the fake repository doesn't have any schema this method does nothing. Simulating errors \u00b6 ConnectionError \u00b6 To simulate a connection error to the database, initialize the object with the wrong_database_url string.","title":"FakeRepository"},{"location":"fake_repository/#features","text":"Follow the overview example to see how to use each method. add Appends the Entity object to the new_entities attribute. delete Deletes the Entity object from the new_entities attribute. get Obtain an Entity from the entities attribute by it's ID. commit Persist the changes of new_entities into entities , clearing up new_entities afterwards. all Obtain all the entities of type Entity from the entities attribute. search Obtain the entities whose attributes match one or multiple conditions. We use DeepDiff's grep to search for the entities that have the value we're searching for and then we search if the key of those entities match the one we're searching for. apply_migrations Run the migrations of the repository schema. As the fake repository doesn't have any schema this method does nothing.","title":"Features"},{"location":"fake_repository/#simulating-errors","text":"","title":"Simulating errors"},{"location":"fake_repository/#connectionerror","text":"To simulate a connection error to the database, initialize the object with the wrong_database_url string.","title":"ConnectionError"},{"location":"file_repositories/","text":"File repositories give a common interface to store computer file contents. They only persist the content of File objects into the different backends. The metadata however is not stored, so you'll need to use a data repository for that. A Simple Example \u00b6 import os from repository_orm import File , load_file_repository repo = load_file_repository ( \"local:/tmp/file_data\" ) file_ = File ( path = \"test.txt\" ) file_ . _content = \"File content\" # Save content in the repository file_ = repo . save ( file_ ) assert file_ . path == \"/tmp/file_data/test.txt\" assert os . path . isfile ( file_ . path ) # Load the content from the repository file_ = File ( path = \"test.txt\" ) file_ = repo . load ( file_ ) assert file_ . content == \"File content\" # Remove the file content from the repository repo . delete ( file_ ) assert not os . path . isfile ( \"/tmp/file_data/test.txt\" ) # noqa Usage \u00b6 The different repositories share the next operations: load Load the content of the file from the persistence system. save Save the content of the file into the persistence system. delete Delete the file from the persistence system. Repositories \u00b6 To change the repository you only need to change the url passed to load_file_repository . We have the next repositories: LocalFileRepository : stores the file contents in the local file system.","title":"File Repositories"},{"location":"file_repositories/#a-simple-example","text":"import os from repository_orm import File , load_file_repository repo = load_file_repository ( \"local:/tmp/file_data\" ) file_ = File ( path = \"test.txt\" ) file_ . _content = \"File content\" # Save content in the repository file_ = repo . save ( file_ ) assert file_ . path == \"/tmp/file_data/test.txt\" assert os . path . isfile ( file_ . path ) # Load the content from the repository file_ = File ( path = \"test.txt\" ) file_ = repo . load ( file_ ) assert file_ . content == \"File content\" # Remove the file content from the repository repo . delete ( file_ ) assert not os . path . isfile ( \"/tmp/file_data/test.txt\" ) # noqa","title":"A Simple Example"},{"location":"file_repositories/#usage","text":"The different repositories share the next operations: load Load the content of the file from the persistence system. save Save the content of the file into the persistence system. delete Delete the file from the persistence system.","title":"Usage"},{"location":"file_repositories/#repositories","text":"To change the repository you only need to change the url passed to load_file_repository . We have the next repositories: LocalFileRepository : stores the file contents in the local file system.","title":"Repositories"},{"location":"local_file_repository/","text":"The LocalFileRepository stores the file contents in the local file system. It stores the File 's contents in a file in the local file system. Imagine you want to save the contents in /srv/file_data , you'll then initialize the repository with: from repository_orm import load_file_repository repo = load_file_repository ( \"local:/srv/file_data\" ) Features \u00b6 Follow the overview example to see how to use each method. load Load the content of the File from a file in the local filesystem. save Save the content of the File to a file in the local filesystem. delete Delete the file from the local filesystem.","title":"LocalFileRepository"},{"location":"local_file_repository/#features","text":"Follow the overview example to see how to use each method. load Load the content of the File from a file in the local filesystem. save Save the content of the File to a file in the local filesystem. delete Delete the file from the local filesystem.","title":"Features"},{"location":"models/","text":"When modeling the application logic through Domain Driven Design , you usually need the following object types: Value object : Any domain object that is uniquely identified by the data it holds, so it has no conceptual identity. They should be treated as immutable. We can still have complex behaviour in value objects. In fact, it's common to support operations, for example, mathematical operators. Entity : An object that is not defined by it's attributes, but rather by a thread of continuity and it's identity. Unlike values, they have identity equality . We can change their values, and they are still recognizably the same thing. Entities \u00b6 The Entity class is based on the pydantic's BaseModel to enforce that they have the id_ attribute of type int , str or AnyHttpUrl , used for comparison and hashing of entities. They also have a private model_name property with the name of the model. If you use integer IDs (which is the default), you don't need to define the id_ at object creation. When you add the entity to the repository, it will populate it. from repository_orm import Entity , load_repository class Author ( Entity ): first_name : str repo = load_repository () author = Author ( first_name = \"Brandon\" ) # Add entities repo . add ( author ) repo . commit () # Retrieve entities by their ID brandon = repo . get ( 0 , Author ) assert brandon == author # noqa !!! warning \"This will only work with int ids! For the rest of the cases you need to give the id_ yourself.\" Merging entities \u00b6 Entities have a merge method that let's you update it's attributes with the ones of another entity. from repository_orm import Entity class Author ( Entity ): name : str is_alive : bool = True author = Author ( name = \"Brandon\" ) # Imagine a complex process here that creates an updated version of the author object new_author = Author ( name = \"New name\" , is_alive = False ) author . merge ( new_author ) assert author . name == \"New name\" assert not author . is_alive # Nevertheless the default values are not merged! author . merge ( Author ( name = \"Brandon\" )) assert not author . is_alive # Unless specified by the user author . merge ( Author ( name = \"Brandon\" , is_alive = True )) assert author . is_alive # noqa For two entities to be mergeable, they need to belong from the same model and have the same id_ . The previous example worked because by default the id_ is -1 until the entity is added to the repository. If you want to check other attribute to see if the objects are mergeable, probably that attribute should be the id_ instead. If you don't want to propagate some attributes when merging, add them to the _skip_on_merge configuration option of the model: from datetime import datetime from repository_orm import Entity class Author ( Entity ): name : str is_alive : bool = True birthday : datetime _skip_on_merge = [ \"birthday\" ] author = Author ( name = \"Brandon\" , birthday = datetime ( 2020 , 1 , 1 )) new_author = Author ( name = \"Brandon\" , birthday = datetime ( 1900 , 1 , 1 ), is_alive = False ) author . merge ( new_author ) assert author . birthday == datetime ( 2020 , 1 , 1 ) assert not author . is_alive # noqa Files \u00b6 The File class is a special Entity model used to work with computer files. It has useful attributes like: path . created_at . updated_at . owner . group . permissions . And methods: basename . dirname . extension . Until Pydantic 1.9 is released, you need to store the content in the file using the _content attribute, to access the content, you can use content directly.","title":"Models"},{"location":"models/#entities","text":"The Entity class is based on the pydantic's BaseModel to enforce that they have the id_ attribute of type int , str or AnyHttpUrl , used for comparison and hashing of entities. They also have a private model_name property with the name of the model. If you use integer IDs (which is the default), you don't need to define the id_ at object creation. When you add the entity to the repository, it will populate it. from repository_orm import Entity , load_repository class Author ( Entity ): first_name : str repo = load_repository () author = Author ( first_name = \"Brandon\" ) # Add entities repo . add ( author ) repo . commit () # Retrieve entities by their ID brandon = repo . get ( 0 , Author ) assert brandon == author # noqa !!! warning \"This will only work with int ids! For the rest of the cases you need to give the id_ yourself.\"","title":"Entities"},{"location":"models/#merging-entities","text":"Entities have a merge method that let's you update it's attributes with the ones of another entity. from repository_orm import Entity class Author ( Entity ): name : str is_alive : bool = True author = Author ( name = \"Brandon\" ) # Imagine a complex process here that creates an updated version of the author object new_author = Author ( name = \"New name\" , is_alive = False ) author . merge ( new_author ) assert author . name == \"New name\" assert not author . is_alive # Nevertheless the default values are not merged! author . merge ( Author ( name = \"Brandon\" )) assert not author . is_alive # Unless specified by the user author . merge ( Author ( name = \"Brandon\" , is_alive = True )) assert author . is_alive # noqa For two entities to be mergeable, they need to belong from the same model and have the same id_ . The previous example worked because by default the id_ is -1 until the entity is added to the repository. If you want to check other attribute to see if the objects are mergeable, probably that attribute should be the id_ instead. If you don't want to propagate some attributes when merging, add them to the _skip_on_merge configuration option of the model: from datetime import datetime from repository_orm import Entity class Author ( Entity ): name : str is_alive : bool = True birthday : datetime _skip_on_merge = [ \"birthday\" ] author = Author ( name = \"Brandon\" , birthday = datetime ( 2020 , 1 , 1 )) new_author = Author ( name = \"Brandon\" , birthday = datetime ( 1900 , 1 , 1 ), is_alive = False ) author . merge ( new_author ) assert author . birthday == datetime ( 2020 , 1 , 1 ) assert not author . is_alive # noqa","title":"Merging entities"},{"location":"models/#files","text":"The File class is a special Entity model used to work with computer files. It has useful attributes like: path . created_at . updated_at . owner . group . permissions . And methods: basename . dirname . extension . Until Pydantic 1.9 is released, you need to store the content in the file using the _content attribute, to access the content, you can use content directly.","title":"Files"},{"location":"new_repo/","text":"First make sure you've read the contributing guidelines . All repository types are run against the same tests . Using the awesome library pytest-cases , we were able to separate the test cases from the test functions. The result is not simple to understand, but bear with me, as once you understand it, you may love it. The test cases are in the cases directory below tests . There are two files: entities.py : Where we define the different Entity objects to test through the methods of the EntityCases class. repositories.py : Where we define the different Repository objects to test through the methods of the RepositoryCases class. The Entity cases, return a factory defined with Factoryboy together with the Entity model, to create arbitrary objects with real values generated through Faker . The Repository cases are a little more complex, each of them returns a tuple with the following objects: db : A storage connection object to run direct queries in the tests. empty_repo : A repository instance without the schema applied. repo : A repository instance with the schema applied. repo_tester : A class to particularize the testing interface to each repository. Each repository needs different assertions to ensure that a functionality works as expected, this fact makes it really difficult to parametrize the tests. The solution I've found is to write the tests Making generic tests for The Entities to test are defined in the The interface definition of all repositories is done at the AbstractRepository class.","title":"Create new repository"},{"location":"pypika_repository/","text":"The PypikaRepository is the implementation of the repository pattern for the relational databases. It's meant for the stages of the project where the schema is more stable and you need the improved performance of these types of databases. It stores the persisted Entities into a SQLite database tables ( Mysql support will come in the future ). It uses the Pypika query builder to generate the raw SQL statements and then sends them to the database through an sqlite3 connection. If you're wondering why we don't want to use SQLAlchemy or raw sql statements, check this article. Load it with: from repository_orm import load_repository repo = load_repository ( 'sqlite://path/to/database.db' ) Database schema \u00b6 The repository assumes there is a specific schema, where the table names are the same as the Entity clases in lowercase, and the columns are called as the attributes. All tables must have an id column. Following the overview example , the database should contain one table called author with the columns id , first_name , last_name and country . For it's simplicity, we've decide to use yoyo to maintain the schema. This means that you need to write the migration scripts yourself :(. Look at the migration script of the tests if you need an example. Features \u00b6 Follow the overview example to see how to use each method. add Appends the Entity object to its table by translating its attributes to the columns. If it already exists, use the upsert statement to update it's attributes in the table. delete Deletes the Entity object from its table by searching the row that matches the object ID. get Obtain an Entity by extracting the row that matches the ID and build the Entity object with that data. commit Persist the changes into the database. all Obtain all the entities of type Entity . Similar to the get method but for all entities. search Obtain the entities whose attributes match one or multiple conditions. We create a query with all the desired criteria and then build the entities with the obtained data. apply_migrations Run the migrations of the repository schema. Creates a yoyo connection and runs all the scripts in the migrations directory. Internal workings \u00b6 This section is meant for the people that you to expand the functionality of the PypikaRepository. It explains how it works under the hood. Once the object is initialized with the database url with the format sqlite:///path_to_database_file , an sqlite3 Connection object is saved in the connection attribute, and a first Cursor is saved to the cursor attribute. If you need to execute new queries, use the _execute method, it accepts a Pypika Query object. To extract the Pypika Table from an identity object, use the _table static method, or the _table_model if you use an identity class instead. Keep in mind that if you use the internal methods, like _execute , in your program, you're breaking the Liskov substitution principle and you won't be able to switch to other type of repository. If you need a functionality that is not implemented, create a public method and define it for the repositories that you want to use. Take a look at the contributing page, and think of adding it to the library. There is also the _build_entities method that accepts an Entity class and a Query and returns a list of the entities built from the data of the query. References \u00b6 Pypika documentation Yoyo documentation","title":"PypikaRepository"},{"location":"pypika_repository/#database-schema","text":"The repository assumes there is a specific schema, where the table names are the same as the Entity clases in lowercase, and the columns are called as the attributes. All tables must have an id column. Following the overview example , the database should contain one table called author with the columns id , first_name , last_name and country . For it's simplicity, we've decide to use yoyo to maintain the schema. This means that you need to write the migration scripts yourself :(. Look at the migration script of the tests if you need an example.","title":"Database schema"},{"location":"pypika_repository/#features","text":"Follow the overview example to see how to use each method. add Appends the Entity object to its table by translating its attributes to the columns. If it already exists, use the upsert statement to update it's attributes in the table. delete Deletes the Entity object from its table by searching the row that matches the object ID. get Obtain an Entity by extracting the row that matches the ID and build the Entity object with that data. commit Persist the changes into the database. all Obtain all the entities of type Entity . Similar to the get method but for all entities. search Obtain the entities whose attributes match one or multiple conditions. We create a query with all the desired criteria and then build the entities with the obtained data. apply_migrations Run the migrations of the repository schema. Creates a yoyo connection and runs all the scripts in the migrations directory.","title":"Features"},{"location":"pypika_repository/#internal-workings","text":"This section is meant for the people that you to expand the functionality of the PypikaRepository. It explains how it works under the hood. Once the object is initialized with the database url with the format sqlite:///path_to_database_file , an sqlite3 Connection object is saved in the connection attribute, and a first Cursor is saved to the cursor attribute. If you need to execute new queries, use the _execute method, it accepts a Pypika Query object. To extract the Pypika Table from an identity object, use the _table static method, or the _table_model if you use an identity class instead. Keep in mind that if you use the internal methods, like _execute , in your program, you're breaking the Liskov substitution principle and you won't be able to switch to other type of repository. If you need a functionality that is not implemented, create a public method and define it for the repositories that you want to use. Take a look at the contributing page, and think of adding it to the library. There is also the _build_entities method that accepts an Entity class and a Query and returns a list of the entities built from the data of the query.","title":"Internal workings"},{"location":"pypika_repository/#references","text":"Pypika documentation Yoyo documentation","title":"References"},{"location":"reference/","text":"repository_orm special \u00b6 Library to ease the implementation of the repository pattern in Python projects. adapters special \u00b6 data special \u00b6 abstract \u00b6 Define the interface of the repositories. Repository ( ABC ) \u00b6 Gather common methods and define the interface of the repositories. Attributes: Name Type Description database_url URL specifying the connection to the database. Source code in repository_orm/adapters/data/abstract.py class Repository ( abc . ABC ): \"\"\"Gather common methods and define the interface of the repositories. Attributes: database_url: URL specifying the connection to the database. \"\"\" @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) @abc . abstractmethod def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. This method is specific to each database adapter. Args: entity: Entity to add to the repository. Returns: entity \"\"\" raise NotImplementedError @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity @abc . abstractmethod def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Particular implementation of the adapter. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" raise NotImplementedError def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities @abc . abstractmethod def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. \"\"\" raise NotImplementedError @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities @abc . abstractmethod def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" raise NotImplementedError @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) def _model_not_found ( self , models : OptionalModelOrModels [ Entity ], append_str : str = \"\" ) -> EntityNotFoundError : \"\"\"Raise the appropriate EntityNotFoundError exception based on models. Args: models: Type of entity object to obtain. append_str: message to append after the message of no entities found. Must start with a space Raises: EntityNotFoundError \"\"\" models = self . _build_models ( models ) entity_str = \", \" . join ([ model . __name__ for model in models ]) return EntityNotFoundError ( f \"There are no entities of type { entity_str } \" f \"in the repository { append_str } .\" ) def _build_models ( self , models : OptionalModelOrModels [ Entity ]) -> Models [ Entity ]: \"\"\"Create the Models from the OptionalModelOrModels.\"\"\" if models is None : models = self . models elif not isinstance ( models , list ): models = [ models ] return models @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None search_exception bool Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. True Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () add ( self , entities , merge = False ) \u00b6 Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If merge is True, added entities will be merged with the existent ones in the cache. Parameters: Name Type Description Default entity Entity to add to the repository. required Returns: Type Description ~EntityOrEntities entity Source code in repository_orm/adapters/data/abstract.py def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) all ( self , models = None ) \u00b6 Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Source code in repository_orm/adapters/data/abstract.py def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError first ( self , models ) \u00b6 Get the smallest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Type of entity object to obtain. required Returns: Type Description entity Smallest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover get ( self , id_ , models = None ) \u00b6 Obtain an entity from the repository by it's ID. Also save the entity in the cache Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None id_ Union[int, str, pydantic.networks.AnyHttpUrl] ID of the entity to obtain. required Returns: Type Description entity Entity object that matches the id_ Exceptions: Type Description EntityNotFoundError If the entity is not found. TooManyEntitiesError If more than one entity was found. Source code in repository_orm/adapters/data/abstract.py def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error next_id ( self , entity ) \u00b6 Return one id unit more than the last entity id in the repository index. Parameters: Name Type Description Default entity ~Entity Entity whose model we want to get the next entity id. required Source code in repository_orm/adapters/data/abstract.py def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) search ( self , fields , models = None ) \u00b6 Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None fields Dict[str, Union[int, str, pydantic.networks.AnyHttpUrl]] Dictionary with the {key}:{value} to search. required Returns: Type Description entities List of Entity object that matches the search criteria. Exceptions: Type Description EntityNotFoundError If the entities are not found. Source code in repository_orm/adapters/data/abstract.py def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities warn_on_models ( models , method ) \u00b6 Warn users that using more than one model is going to be deprecated. Source code in repository_orm/adapters/data/abstract.py def warn_on_models ( models : OptionalModelOrModels [ Entity ], method : str ) -> None : \"\"\"Warn users that using more than one model is going to be deprecated.\"\"\" if isinstance ( models , list ): warnings . warn ( f \"In 2022-06-10 using repo. { method } with a list of models is going to be \" \"deprecated, please use just one model instead\" , UserWarning , ) elif models is None : warnings . warn ( f \"In 2022-06-10 using repo. { method } without any model is going to be \" \"deprecated, please set the model you want to use.\" , UserWarning , ) cache \u00b6 Define the cache of the data repositories. Cache \u00b6 Define the cache of a repository. The entries are saved in the cache attribute under a dictionary similar to: { !!! model_1 \"{\" Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } Source code in repository_orm/adapters/data/cache.py class Cache : \"\"\"Define the cache of a repository. The entries are saved in the `cache` attribute under a dictionary similar to: { Model_1: { Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ ) __init__ ( self ) special \u00b6 Initialize the class. Source code in repository_orm/adapters/data/cache.py def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} add ( self , entity_or_entities ) \u00b6 Add an entity to the cache. Source code in repository_orm/adapters/data/cache.py def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) entity_has_not_changed ( self , entity ) \u00b6 Check if entity is equal to the version in the cache. Source code in repository_orm/adapters/data/cache.py def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False get ( self , entity ) \u00b6 Return the cached value of an entity. Source code in repository_orm/adapters/data/cache.py def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] remove ( self , entity_or_entities ) \u00b6 Remove an entity from the cache if it exists. Source code in repository_orm/adapters/data/cache.py def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ ) fake \u00b6 Store the fake repository implementation. FakeRepository ( Repository ) \u00b6 Implement the repository pattern using a memory dictionary. Source code in repository_orm/adapters/data/fake.py class FakeRepository ( Repository ): \"\"\"Implement the repository pattern using a memory dictionary.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] except KeyError : self . new_entities [ type ( entity )] = {} self . new_entities [ type ( entity )][ entity . id_ ] = entity return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): matching_entities . append ( self . entities [ model ][ id_ ]) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] . copy () if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): entities += sorted ( entity for entity_id , entity in self . entities [ model ] . items () ) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" models = self . _build_models ( models ) if len ( models ) == 1 : models = models [ 0 ] all_entities : List [ Entity ] = self . all ( models ) entities_dict = { entity . id_ : entity for entity in all_entities } entity_attributes = { entity . id_ : entity . dict () for entity in all_entities } for key , value in fields . items (): # Get entities that have the value `value` entities_with_value = entity_attributes | grep ( value , use_regexp = True , strict_checking = False ) matching_entity_attributes = {} try : entities_with_value [ \"matched_values\" ] except KeyError as error : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) from error for path in entities_with_value [ \"matched_values\" ]: entity_id = re . sub ( r \"root\\['?(.*?)'?\\]\\[.*\" , r \"\\1\" , path ) # Convert int ids from str to int try : entity_id = int ( entity_id ) except ValueError : entity_id = re . sub ( r \"'(.*)'\" , r \"\\1\" , entity_id ) # Add the entity to the matching ones only if the value is of the # attribute `key`. if re . match ( rf \"root\\['? { entity_id } '?\\]\\[' { key } '\\]\" , path ): matching_entity_attributes [ entity_id ] = extract ( entity_attributes , f \"root[ { entity_id } ]\" ) entity_attributes = matching_entity_attributes entities = [ entities_dict [ key ] for key in entity_attributes . keys ()] return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def _staged_entities ( self , models : Models [ Entity ]) -> List [ Entity ]: \"\"\"Return a list of staged entities of type models. Args: models: Return only instances of these models. \"\"\" staged_entities = [] for model in models : staged_entities += [ entity for _ , entity in self . new_entities [ model ] . items () ] return staged_entities def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Source code in repository_orm/adapters/data/fake.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/fake.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/fake.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/fake.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/fake.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/fake.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) pypika \u00b6 Define the Pypika Repository. PypikaRepository ( Repository ) \u00b6 Implement the repository pattern using the Pypika query builder. Source code in repository_orm/adapters/data/pypika.py class PypikaRepository ( Repository ): \"\"\"Implement the repository pattern using the Pypika query builder.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () def _execute ( self , query : Union [ Query , str ]) -> sqlite3 . Cursor : \"\"\"Execute an SQL statement from a Pypika query object. Args: query: Pypika query \"\"\" return self . cursor . execute ( str ( query )) @staticmethod def _table ( entity : Entity ) -> Table : \"\"\"Return the table of the selected entity object.\"\"\" return Table ( entity . model_name . lower ()) @staticmethod def _table_model ( model : Type [ Entity ]) -> Table : \"\"\"Return the table of the selected entity class.\"\"\" return Table ( model . __name__ . lower ()) def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" table = self . _table ( entity ) columns = list ( entity . dict () . keys ()) columns [ columns . index ( \"id_\" )] = \"id\" values = [ value for key , value in entity . dict () . items ()] insert_query = Query . into ( table ) . columns ( tuple ( columns )) . insert ( tuple ( values )) # Until https://github.com/kayak/pypika/issues/535 is solved we need to write # The upsert statement ourselves. # nosec: B608:hardcoded_sql_expressions, Possible SQL injection vector through # string-based query construction. We're not letting the user define the # values of the query, the only variable inputs are the keys, that are # defined by the developer, so it's not probable that he chooses an # entity attributes that are an SQL injection. Once the #535 issue is # solved, we should get rid of this error too. upsert_query = ( str ( insert_query ) + \" ON CONFLICT(id) DO UPDATE SET \" # nosec + \", \" . join ([ f \" { key } =excluded. { key } \" for key in columns ]) ) self . _execute ( upsert_query ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) . where ( table . id == id_ ) matching_entities += self . _build_entities ( model , query ) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) entities += self . _build_entities ( model , query ) return entities def _build_entities ( self , model : Type [ Entity ], query : Query ) -> List [ Entity ]: \"\"\"Build Entity objects from the data extracted from the database. Args: models: The model of the entity to build query: pypika query of the entities you want to build \"\"\" cursor = self . _execute ( query ) entities_data = cursor . fetchall () attributes = [ description [ 0 ] for description in cursor . description ] entities : List [ Entity ] = [] for entity_data in entities_data : entity_dict = { attributes [ index ]: entity_data [ index ] for index in range ( 0 , len ( entity_data )) } entity_dict [ \"id_\" ] = entity_dict . pop ( \"id\" ) entities . append ( model ( ** entity_dict )) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) for key , value in fields . items (): if key == \"id_\" : key = \"id\" if isinstance ( value , str ): query = query . where ( functions . Lower ( getattr ( table , key )) . regexp ( value . lower ()) ) else : query = query . where ( getattr ( table , key ) == value ) with suppress ( OperationalError ): entities += self . _build_entities ( model , query ) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close () __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/pypika.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/pypika.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/pypika.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close () commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/pypika.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/pypika.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) tinydb \u00b6 Define the TinyDB Repository. TinyDBRepository ( Repository ) \u00b6 Implement the repository pattern using the TinyDB. Source code in repository_orm/adapters/data/tinydb.py class TinyDBRepository ( Repository ): \"\"\"Implement the repository pattern using the TinyDB.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" self . staged [ \"add\" ] . append ( entity ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" models = self . _build_models ( models ) model_query = self . _build_model_query ( models ) matching_entities_data = self . db_ . search (( Query () . id_ == id_ ) & ( model_query )) if len ( matching_entities_data ) == 1 : return self . _build_entity ( matching_entities_data [ 0 ], models ) if len ( matching_entities_data ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _build_entity ( self , entity_data : Dict [ Any , Any ], models : OptionalModelOrModels [ Entity ] = None , ) -> Entity : \"\"\"Create an entity from the data stored in a row of the database. Args: entity_data: Dictionary with the attributes of the entity. models: Type of entity object to obtain. Returns: entity: Built Entity. \"\"\" # If we don't copy the data, the all method stop being idempotent. entity_data = entity_data . copy () model_name = entity_data . pop ( \"model_type_\" ) models = self . _build_models ( models ) for model in models : if model . schema ()[ \"title\" ] . lower () == model_name : try : return model . parse_obj ( entity_data ) except ValidationError as error : log . error ( f \"Error loading the model { model_name . capitalize () } \" f \"for the register { str ( entity_data ) } \" ) raise error # no cover: this code is going to disappear soon, it makes no sense to create # a new test raise ValueError ( f \"No model found with name { model_name } \" ) # pragma: no cover def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) if models == self . models : entities_data = self . db_ . all () else : query = self . _build_model_query ( models ) entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) return entities @staticmethod def _export_entity ( entity : Entity ) -> Dict [ Any , Any ]: \"\"\"Export the attributes of the entity appending the required by TinyDB. Args: entity: Entity to export. Returns: entity_data: Dictionary with the attributes of the entity. \"\"\" entity_data = entity . dict () entity_data [ \"model_type_\" ] = entity . model_name . lower () return entity_data def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) query = self . _build_search_query ( fields , models ) # Build entities entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def _build_search_query ( self , fields : Dict [ str , EntityID ], models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts for a repository search. Select only the models that contain the fields. If the field type is a list, change the query accordingly. Args: models: Type of entity object to obtain. fields: Dictionary with the {key}:{value} to search. Returns: Query based on the type of models and fields. \"\"\" query_parts = [] for model in models : model_query_parts = [] schema = model . schema ()[ \"properties\" ] for field , value in fields . items (): if field not in schema . keys (): continue with suppress ( KeyError ): if schema [ field ][ \"type\" ] == \"array\" : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . test ( _regexp_in_list , value )) ) continue if isinstance ( value , str ): model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . search ( value , flags = re . IGNORECASE )) ) else : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] == value ) ) if len ( model_query_parts ) != 0 : query_parts . append ( self . _merge_query ( model_query_parts , mode = \"and\" )) if len ( query_parts ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return self . _merge_query ( query_parts , mode = \"or\" ) def _build_model_query ( self , models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts from the models. Args: models: Type of entity object to obtain. Returns: List of query parts based on the type of models \"\"\" query_parts = [] for model in models : query_parts . append ( Query () . model_type_ == model . __name__ . lower ()) return self . _merge_query ( query_parts , mode = \"or\" ) @staticmethod def _merge_query ( query_parts : List [ QueryInstance ], mode : str = \"and\" ) -> QueryInstance : \"\"\"Join all the query parts into a query. Args: query_parts: List of queries to concatenate. mode: \"and\" or \"or\" for the join method. Returns: A query object that joins all parts. \"\"\" query = query_parts [ 0 ] for query_part in query_parts [ 1 :]: if mode == \"and\" : query = query & query_part else : query = query | query_part return query def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close () __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/tinydb.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/tinydb.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/tinydb.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close () commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/tinydb.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/tinydb.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/tinydb.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) file special \u00b6 abstract \u00b6 Define the abstract interface for file repositories. FileRepository ( BaseModel , ABC , Generic ) pydantic-model \u00b6 Define the interface of the file repositories. Source code in repository_orm/adapters/file/abstract.py class FileRepository ( BaseModel , ABC , Generic [ AnyStr ]): \"\"\"Define the interface of the file repositories.\"\"\" workdir : str = \".\" @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_ delete ( self , file_ ) \u00b6 Delete the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError fix_path ( self , file_ ) \u00b6 Update the path to include the workdir. Source code in repository_orm/adapters/file/abstract.py def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_ load ( self , file_ ) \u00b6 Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError save ( self , file_ ) \u00b6 Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError local_file \u00b6 Define the local filesystem adapter. LocalFileRepository ( FileRepository ) pydantic-model \u00b6 Define the local filesystem adapter. Source code in repository_orm/adapters/file/local_file.py class LocalFileRepository ( FileRepository [ AnyStr ]): \"\"\"Define the local filesystem adapter.\"\"\" def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_ def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" ) __init__ ( self , workdir ) special \u00b6 Initialize the object. Creates the working directory if it doesn't exist. Source code in repository_orm/adapters/file/local_file.py def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) delete ( self , file_ ) \u00b6 Delete the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" ) load ( self , file_ ) \u00b6 Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ save ( self , file_ ) \u00b6 Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/local_file.py def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_ config \u00b6 Define the configuration of the main program. exceptions \u00b6 Store the repository-orm exceptions. AutoIncrementError ( Exception ) \u00b6 Raised when the id_ auto increment repository feature fails. Source code in repository_orm/exceptions.py class AutoIncrementError ( Exception ): \"\"\"Raised when the id_ auto increment repository feature fails.\"\"\" EntityNotFoundError ( Exception ) \u00b6 Raised when the search or retrieve of an entity fails. Source code in repository_orm/exceptions.py class EntityNotFoundError ( Exception ): \"\"\"Raised when the search or retrieve of an entity fails.\"\"\" FileContentNotLoadedError ( Exception ) \u00b6 Raised when trying to access the content of a file that has not been loaded. Source code in repository_orm/exceptions.py class FileContentNotLoadedError ( Exception ): \"\"\"Raised when trying to access the content of a file that has not been loaded.\"\"\" TooManyEntitiesError ( Exception ) \u00b6 Raised when more entities than expected where found. Source code in repository_orm/exceptions.py class TooManyEntitiesError ( Exception ): \"\"\"Raised when more entities than expected where found.\"\"\" model \u00b6 Store the common business model of all entities. Entity ( BaseModel ) pydantic-model \u00b6 Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have identity equality . We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. Source code in repository_orm/model.py class Entity ( BaseModel ): \"\"\"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have *identity equality*. We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. \"\"\" id_ : EntityID = - 1 _defined_values : Dict [ str , Any ] = PrivateAttr () _skip_on_merge : List [ str ] = [] def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) @property def model_name ( self ) -> str : \"\"\"Return the entity model name.\"\"\" return self . __class__ . __name__ @property def _model_name ( self ) -> str : # pragma: nocover \"\"\"Return the entity model name.\"\"\" warnings . warn ( \"Use model_name instead before 2022-06-10\" , DeprecationWarning ) return self . model_name def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self @property def defined_values ( self ) -> Dict [ str , Any ]: \"\"\"Return the entity defined values.\"\"\" return self . _defined_values def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {} defined_values : Dict [ str , Any ] property readonly \u00b6 Return the entity defined values. model_name : str property readonly \u00b6 Return the entity model name. __gt__ ( self , other ) special \u00b6 Assert if an object is greater than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) __hash__ ( self ) special \u00b6 Create an unique hash of the class object. Source code in repository_orm/model.py def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) __init__ ( self , ** data ) special \u00b6 Initialize the defined values. Source code in repository_orm/model.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data __lt__ ( self , other ) special \u00b6 Assert if an object is smaller than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) __setattr__ ( self , attribute , value ) special \u00b6 Store the set attribute into the _defined_values. Source code in repository_orm/model.py def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) clear_defined_values ( self ) \u00b6 Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error Incompatible return value type (got \"Entity\", expected \"Entity\") Source code in repository_orm/model.py def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {} merge ( self , other ) \u00b6 Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to self . Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self File ( Entity , Generic ) pydantic-model \u00b6 Model a computer file. Source code in repository_orm/model.py class File ( Entity , Generic [ AnyStr ]): \"\"\"Model a computer file.\"\"\" path : str created_at : Optional [ datetime ] = None updated_at : Optional [ datetime ] = None owner : Optional [ str ] = None group : Optional [ str ] = None permissions : Optional [ str ] = None # The use of a private attribute and the impossibility of loading the content # at object creation will be fixed on Pydantic 1.9. # We will be able to define the excluded attribute content in the Config of the # model. # # For more information on how to improve this code, read this: # https://lyz-code.github.io/blue-book/coding/python/pydantic/#define-fields-to-exclude-from-exporting-at-config-level # noqa:E501 _content : Optional [ AnyStr ] = PrivateAttr ( None ) # If the content is of type bytes is_bytes : bool = False @property def basename ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . basename ( self . path ) @property def dirname ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . dirname ( self . path ) @property def extension ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return self . basename . split ( \".\" )[ - 1 ] @property def content ( self ) -> AnyStr : \"\"\"Return the content of the file. Returns: The content of the file. Raises: FileContentNotLoadedError: if the content is not yet loaded. \"\"\" if self . _content is None : raise FileContentNotLoadedError ( \"The content of the file has not been loaded yet.\" ) return self . _content basename : str property readonly \u00b6 Return the name of the file. content : ~ AnyStr property readonly \u00b6 Return the content of the file. Returns: Type Description ~AnyStr The content of the file. Exceptions: Type Description FileContentNotLoadedError if the content is not yet loaded. dirname : str property readonly \u00b6 Return the name of the file. extension : str property readonly \u00b6 Return the name of the file. services \u00b6 Define all the orchestration functionality required by the program to work. Classes and functions that connect the different domain model objects with the adapters and handlers to achieve the program's purpose. load_file_repository ( url = 'local:.' ) \u00b6 Load the FileRepository object that matches the url protocol. Parameters: Name Type Description Default url str Url to connect to the storage backend. 'local:.' Returns: Type Description FileRepository[AnyStr] File Repository that understands the url protocol. Source code in repository_orm/services.py def load_file_repository ( url : str = \"local:.\" ) -> \"FileRepository[AnyStr]\" : \"\"\"Load the FileRepository object that matches the url protocol. Args: url: Url to connect to the storage backend. Returns: File Repository that understands the url protocol. \"\"\" if \"local:\" in url : return LocalFileRepository ( workdir = url . split ( \":\" )[ 1 ]) raise ValueError ( f \"File Repository URL: { url } not recognized.\" ) load_repository ( database_url = 'fake://' , models = None , search_exception = True ) \u00b6 Load the Repository object that matches the database url protocol. Parameters: Name Type Description Default database_url str Url to connect to the storage backend. 'fake://' Returns: Type Description Union[repository_orm.adapters.data.fake.FakeRepository, repository_orm.adapters.data.pypika.PypikaRepository, repository_orm.adapters.data.tinydb.TinyDBRepository] Repository that understands the url protocol. Source code in repository_orm/services.py def load_repository ( database_url : str = \"fake://\" , models : Optional [ Models [ Entity ]] = None , search_exception : bool = True , ) -> Repository : \"\"\"Load the Repository object that matches the database url protocol. Args: database_url: Url to connect to the storage backend. Returns: Repository that understands the url protocol. \"\"\" if \"fake://\" in database_url : return FakeRepository ( models , \"\" , search_exception ) if \"sqlite://\" in database_url : return PypikaRepository ( models , database_url , search_exception ) if \"tinydb://\" in database_url : return TinyDBRepository ( models , database_url , search_exception ) raise ValueError ( f \"Database URL: { database_url } not recognized.\" ) version \u00b6 Utilities to retrieve the information of the program version. version_info () \u00b6 Display the version of the program, python and the platform. Source code in repository_orm/version.py def version_info () -> str : \"\"\"Display the version of the program, python and the platform.\"\"\" info = { \"repository_orm version\" : __version__ , \"python version\" : sys . version . replace ( \" \\n \" , \" \" ), \"platform\" : platform . platform (), } return \" \\n \" . join ( f \" { k + ':' : >30 } { v } \" for k , v in info . items ())","title":"Reference"},{"location":"reference/#repository_orm","text":"Library to ease the implementation of the repository pattern in Python projects.","title":"repository_orm"},{"location":"reference/#repository_orm.adapters","text":"","title":"adapters"},{"location":"reference/#repository_orm.adapters.data","text":"","title":"data"},{"location":"reference/#repository_orm.adapters.data.abstract","text":"Define the interface of the repositories.","title":"abstract"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository","text":"Gather common methods and define the interface of the repositories. Attributes: Name Type Description database_url URL specifying the connection to the database. Source code in repository_orm/adapters/data/abstract.py class Repository ( abc . ABC ): \"\"\"Gather common methods and define the interface of the repositories. Attributes: database_url: URL specifying the connection to the database. \"\"\" @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) @abc . abstractmethod def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. This method is specific to each database adapter. Args: entity: Entity to add to the repository. Returns: entity \"\"\" raise NotImplementedError @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity @abc . abstractmethod def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Particular implementation of the adapter. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" raise NotImplementedError def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities @abc . abstractmethod def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. \"\"\" raise NotImplementedError @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities @abc . abstractmethod def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" raise NotImplementedError @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) def _model_not_found ( self , models : OptionalModelOrModels [ Entity ], append_str : str = \"\" ) -> EntityNotFoundError : \"\"\"Raise the appropriate EntityNotFoundError exception based on models. Args: models: Type of entity object to obtain. append_str: message to append after the message of no entities found. Must start with a space Raises: EntityNotFoundError \"\"\" models = self . _build_models ( models ) entity_str = \", \" . join ([ model . __name__ for model in models ]) return EntityNotFoundError ( f \"There are no entities of type { entity_str } \" f \"in the repository { append_str } .\" ) def _build_models ( self , models : OptionalModelOrModels [ Entity ]) -> Models [ Entity ]: \"\"\"Create the Models from the OptionalModelOrModels.\"\"\" if models is None : models = self . models elif not isinstance ( models , list ): models = [ models ] return models @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError","title":"Repository"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None search_exception bool Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. True Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache ()","title":"__init__()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.add","text":"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If merge is True, added entities will be merged with the existent ones in the cache. Parameters: Name Type Description Default entity Entity to add to the repository. required Returns: Type Description ~EntityOrEntities entity Source code in repository_orm/adapters/data/abstract.py def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" )","title":"add()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.all","text":"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Source code in repository_orm/adapters/data/abstract.py def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities","title":"all()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError","title":"apply_migrations()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError","title":"close()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError","title":"commit()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError","title":"delete()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.first","text":"Get the smallest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Type of entity object to obtain. required Returns: Type Description entity Smallest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover","title":"first()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.get","text":"Obtain an entity from the repository by it's ID. Also save the entity in the cache Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None id_ Union[int, str, pydantic.networks.AnyHttpUrl] ID of the entity to obtain. required Returns: Type Description entity Entity object that matches the id_ Exceptions: Type Description EntityNotFoundError If the entity is not found. TooManyEntitiesError If more than one entity was found. Source code in repository_orm/adapters/data/abstract.py def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity","title":"get()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error","title":"last()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.next_id","text":"Return one id unit more than the last entity id in the repository index. Parameters: Name Type Description Default entity ~Entity Entity whose model we want to get the next entity id. required Source code in repository_orm/adapters/data/abstract.py def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" )","title":"next_id()"},{"location":"reference/#repository_orm.adapters.data.abstract.Repository.search","text":"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None fields Dict[str, Union[int, str, pydantic.networks.AnyHttpUrl]] Dictionary with the {key}:{value} to search. required Returns: Type Description entities List of Entity object that matches the search criteria. Exceptions: Type Description EntityNotFoundError If the entities are not found. Source code in repository_orm/adapters/data/abstract.py def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities","title":"search()"},{"location":"reference/#repository_orm.adapters.data.abstract.warn_on_models","text":"Warn users that using more than one model is going to be deprecated. Source code in repository_orm/adapters/data/abstract.py def warn_on_models ( models : OptionalModelOrModels [ Entity ], method : str ) -> None : \"\"\"Warn users that using more than one model is going to be deprecated.\"\"\" if isinstance ( models , list ): warnings . warn ( f \"In 2022-06-10 using repo. { method } with a list of models is going to be \" \"deprecated, please use just one model instead\" , UserWarning , ) elif models is None : warnings . warn ( f \"In 2022-06-10 using repo. { method } without any model is going to be \" \"deprecated, please set the model you want to use.\" , UserWarning , )","title":"warn_on_models()"},{"location":"reference/#repository_orm.adapters.data.cache","text":"Define the cache of the data repositories.","title":"cache"},{"location":"reference/#repository_orm.adapters.data.cache.Cache","text":"Define the cache of a repository. The entries are saved in the cache attribute under a dictionary similar to: { !!! model_1 \"{\" Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } Source code in repository_orm/adapters/data/cache.py class Cache : \"\"\"Define the cache of a repository. The entries are saved in the `cache` attribute under a dictionary similar to: { Model_1: { Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ )","title":"Cache"},{"location":"reference/#repository_orm.adapters.data.cache.Cache.__init__","text":"Initialize the class. Source code in repository_orm/adapters/data/cache.py def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {}","title":"__init__()"},{"location":"reference/#repository_orm.adapters.data.cache.Cache.add","text":"Add an entity to the cache. Source code in repository_orm/adapters/data/cache.py def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ())","title":"add()"},{"location":"reference/#repository_orm.adapters.data.cache.Cache.entity_has_not_changed","text":"Check if entity is equal to the version in the cache. Source code in repository_orm/adapters/data/cache.py def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False","title":"entity_has_not_changed()"},{"location":"reference/#repository_orm.adapters.data.cache.Cache.get","text":"Return the cached value of an entity. Source code in repository_orm/adapters/data/cache.py def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ]","title":"get()"},{"location":"reference/#repository_orm.adapters.data.cache.Cache.remove","text":"Remove an entity from the cache if it exists. Source code in repository_orm/adapters/data/cache.py def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ )","title":"remove()"},{"location":"reference/#repository_orm.adapters.data.fake","text":"Store the fake repository implementation.","title":"fake"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository","text":"Implement the repository pattern using a memory dictionary. Source code in repository_orm/adapters/data/fake.py class FakeRepository ( Repository ): \"\"\"Implement the repository pattern using a memory dictionary.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] except KeyError : self . new_entities [ type ( entity )] = {} self . new_entities [ type ( entity )][ entity . id_ ] = entity return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): matching_entities . append ( self . entities [ model ][ id_ ]) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] . copy () if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): entities += sorted ( entity for entity_id , entity in self . entities [ model ] . items () ) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" models = self . _build_models ( models ) if len ( models ) == 1 : models = models [ 0 ] all_entities : List [ Entity ] = self . all ( models ) entities_dict = { entity . id_ : entity for entity in all_entities } entity_attributes = { entity . id_ : entity . dict () for entity in all_entities } for key , value in fields . items (): # Get entities that have the value `value` entities_with_value = entity_attributes | grep ( value , use_regexp = True , strict_checking = False ) matching_entity_attributes = {} try : entities_with_value [ \"matched_values\" ] except KeyError as error : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) from error for path in entities_with_value [ \"matched_values\" ]: entity_id = re . sub ( r \"root\\['?(.*?)'?\\]\\[.*\" , r \"\\1\" , path ) # Convert int ids from str to int try : entity_id = int ( entity_id ) except ValueError : entity_id = re . sub ( r \"'(.*)'\" , r \"\\1\" , entity_id ) # Add the entity to the matching ones only if the value is of the # attribute `key`. if re . match ( rf \"root\\['? { entity_id } '?\\]\\[' { key } '\\]\" , path ): matching_entity_attributes [ entity_id ] = extract ( entity_attributes , f \"root[ { entity_id } ]\" ) entity_attributes = matching_entity_attributes entities = [ entities_dict [ key ] for key in entity_attributes . keys ()] return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def _staged_entities ( self , models : Models [ Entity ]) -> List [ Entity ]: \"\"\"Return a list of staged entities of type models. Args: models: Return only instances of these models. \"\"\" staged_entities = [] for model in models : staged_entities += [ entity for _ , entity in self . new_entities [ model ] . items () ] return staged_entities def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True","title":"FakeRepository"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.__init__","text":"Initialize the repository attributes. Source code in repository_orm/adapters/data/fake.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False","title":"__init__()"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/fake.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema","title":"apply_migrations()"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/fake.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True","title":"close()"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/fake.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {}","title":"commit()"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/fake.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error","title":"delete()"},{"location":"reference/#repository_orm.adapters.data.fake.FakeRepository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/fake.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ])","title":"last()"},{"location":"reference/#repository_orm.adapters.data.pypika","text":"Define the Pypika Repository.","title":"pypika"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository","text":"Implement the repository pattern using the Pypika query builder. Source code in repository_orm/adapters/data/pypika.py class PypikaRepository ( Repository ): \"\"\"Implement the repository pattern using the Pypika query builder.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () def _execute ( self , query : Union [ Query , str ]) -> sqlite3 . Cursor : \"\"\"Execute an SQL statement from a Pypika query object. Args: query: Pypika query \"\"\" return self . cursor . execute ( str ( query )) @staticmethod def _table ( entity : Entity ) -> Table : \"\"\"Return the table of the selected entity object.\"\"\" return Table ( entity . model_name . lower ()) @staticmethod def _table_model ( model : Type [ Entity ]) -> Table : \"\"\"Return the table of the selected entity class.\"\"\" return Table ( model . __name__ . lower ()) def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" table = self . _table ( entity ) columns = list ( entity . dict () . keys ()) columns [ columns . index ( \"id_\" )] = \"id\" values = [ value for key , value in entity . dict () . items ()] insert_query = Query . into ( table ) . columns ( tuple ( columns )) . insert ( tuple ( values )) # Until https://github.com/kayak/pypika/issues/535 is solved we need to write # The upsert statement ourselves. # nosec: B608:hardcoded_sql_expressions, Possible SQL injection vector through # string-based query construction. We're not letting the user define the # values of the query, the only variable inputs are the keys, that are # defined by the developer, so it's not probable that he chooses an # entity attributes that are an SQL injection. Once the #535 issue is # solved, we should get rid of this error too. upsert_query = ( str ( insert_query ) + \" ON CONFLICT(id) DO UPDATE SET \" # nosec + \", \" . join ([ f \" { key } =excluded. { key } \" for key in columns ]) ) self . _execute ( upsert_query ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) . where ( table . id == id_ ) matching_entities += self . _build_entities ( model , query ) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) entities += self . _build_entities ( model , query ) return entities def _build_entities ( self , model : Type [ Entity ], query : Query ) -> List [ Entity ]: \"\"\"Build Entity objects from the data extracted from the database. Args: models: The model of the entity to build query: pypika query of the entities you want to build \"\"\" cursor = self . _execute ( query ) entities_data = cursor . fetchall () attributes = [ description [ 0 ] for description in cursor . description ] entities : List [ Entity ] = [] for entity_data in entities_data : entity_dict = { attributes [ index ]: entity_data [ index ] for index in range ( 0 , len ( entity_data )) } entity_dict [ \"id_\" ] = entity_dict . pop ( \"id\" ) entities . append ( model ( ** entity_dict )) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) for key , value in fields . items (): if key == \"id_\" : key = \"id\" if isinstance ( value , str ): query = query . where ( functions . Lower ( getattr ( table , key )) . regexp ( value . lower ()) ) else : query = query . where ( getattr ( table , key ) == value ) with suppress ( OperationalError ): entities += self . _build_entities ( model , query ) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close ()","title":"PypikaRepository"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/pypika.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor ()","title":"__init__()"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/pypika.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" )","title":"apply_migrations()"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/pypika.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close ()","title":"close()"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/pypika.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit ()","title":"commit()"},{"location":"reference/#repository_orm.adapters.data.pypika.PypikaRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/pypika.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query )","title":"delete()"},{"location":"reference/#repository_orm.adapters.data.tinydb","text":"Define the TinyDB Repository.","title":"tinydb"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository","text":"Implement the repository pattern using the TinyDB. Source code in repository_orm/adapters/data/tinydb.py class TinyDBRepository ( Repository ): \"\"\"Implement the repository pattern using the TinyDB.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" self . staged [ \"add\" ] . append ( entity ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" models = self . _build_models ( models ) model_query = self . _build_model_query ( models ) matching_entities_data = self . db_ . search (( Query () . id_ == id_ ) & ( model_query )) if len ( matching_entities_data ) == 1 : return self . _build_entity ( matching_entities_data [ 0 ], models ) if len ( matching_entities_data ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _build_entity ( self , entity_data : Dict [ Any , Any ], models : OptionalModelOrModels [ Entity ] = None , ) -> Entity : \"\"\"Create an entity from the data stored in a row of the database. Args: entity_data: Dictionary with the attributes of the entity. models: Type of entity object to obtain. Returns: entity: Built Entity. \"\"\" # If we don't copy the data, the all method stop being idempotent. entity_data = entity_data . copy () model_name = entity_data . pop ( \"model_type_\" ) models = self . _build_models ( models ) for model in models : if model . schema ()[ \"title\" ] . lower () == model_name : try : return model . parse_obj ( entity_data ) except ValidationError as error : log . error ( f \"Error loading the model { model_name . capitalize () } \" f \"for the register { str ( entity_data ) } \" ) raise error # no cover: this code is going to disappear soon, it makes no sense to create # a new test raise ValueError ( f \"No model found with name { model_name } \" ) # pragma: no cover def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) if models == self . models : entities_data = self . db_ . all () else : query = self . _build_model_query ( models ) entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) return entities @staticmethod def _export_entity ( entity : Entity ) -> Dict [ Any , Any ]: \"\"\"Export the attributes of the entity appending the required by TinyDB. Args: entity: Entity to export. Returns: entity_data: Dictionary with the attributes of the entity. \"\"\" entity_data = entity . dict () entity_data [ \"model_type_\" ] = entity . model_name . lower () return entity_data def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) query = self . _build_search_query ( fields , models ) # Build entities entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def _build_search_query ( self , fields : Dict [ str , EntityID ], models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts for a repository search. Select only the models that contain the fields. If the field type is a list, change the query accordingly. Args: models: Type of entity object to obtain. fields: Dictionary with the {key}:{value} to search. Returns: Query based on the type of models and fields. \"\"\" query_parts = [] for model in models : model_query_parts = [] schema = model . schema ()[ \"properties\" ] for field , value in fields . items (): if field not in schema . keys (): continue with suppress ( KeyError ): if schema [ field ][ \"type\" ] == \"array\" : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . test ( _regexp_in_list , value )) ) continue if isinstance ( value , str ): model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . search ( value , flags = re . IGNORECASE )) ) else : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] == value ) ) if len ( model_query_parts ) != 0 : query_parts . append ( self . _merge_query ( model_query_parts , mode = \"and\" )) if len ( query_parts ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return self . _merge_query ( query_parts , mode = \"or\" ) def _build_model_query ( self , models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts from the models. Args: models: Type of entity object to obtain. Returns: List of query parts based on the type of models \"\"\" query_parts = [] for model in models : query_parts . append ( Query () . model_type_ == model . __name__ . lower ()) return self . _merge_query ( query_parts , mode = \"or\" ) @staticmethod def _merge_query ( query_parts : List [ QueryInstance ], mode : str = \"and\" ) -> QueryInstance : \"\"\"Join all the query parts into a query. Args: query_parts: List of queries to concatenate. mode: \"and\" or \"or\" for the join method. Returns: A query object that joins all parts. \"\"\" query = query_parts [ 0 ] for query_part in query_parts [ 1 :]: if mode == \"and\" : query = query & query_part else : query = query | query_part return query def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close ()","title":"TinyDBRepository"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/tinydb.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []}","title":"__init__()"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/tinydb.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError","title":"apply_migrations()"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/tinydb.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close ()","title":"close()"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/tinydb.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear ()","title":"commit()"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/tinydb.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity )","title":"delete()"},{"location":"reference/#repository_orm.adapters.data.tinydb.TinyDBRepository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/tinydb.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ])","title":"last()"},{"location":"reference/#repository_orm.adapters.file","text":"","title":"file"},{"location":"reference/#repository_orm.adapters.file.abstract","text":"Define the abstract interface for file repositories.","title":"abstract"},{"location":"reference/#repository_orm.adapters.file.abstract.FileRepository","text":"Define the interface of the file repositories. Source code in repository_orm/adapters/file/abstract.py class FileRepository ( BaseModel , ABC , Generic [ AnyStr ]): \"\"\"Define the interface of the file repositories.\"\"\" workdir : str = \".\" @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_","title":"FileRepository"},{"location":"reference/#repository_orm.adapters.file.abstract.FileRepository.delete","text":"Delete the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError","title":"delete()"},{"location":"reference/#repository_orm.adapters.file.abstract.FileRepository.fix_path","text":"Update the path to include the workdir. Source code in repository_orm/adapters/file/abstract.py def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_","title":"fix_path()"},{"location":"reference/#repository_orm.adapters.file.abstract.FileRepository.load","text":"Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError","title":"load()"},{"location":"reference/#repository_orm.adapters.file.abstract.FileRepository.save","text":"Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError","title":"save()"},{"location":"reference/#repository_orm.adapters.file.local_file","text":"Define the local filesystem adapter.","title":"local_file"},{"location":"reference/#repository_orm.adapters.file.local_file.LocalFileRepository","text":"Define the local filesystem adapter. Source code in repository_orm/adapters/file/local_file.py class LocalFileRepository ( FileRepository [ AnyStr ]): \"\"\"Define the local filesystem adapter.\"\"\" def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_ def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" )","title":"LocalFileRepository"},{"location":"reference/#repository_orm.adapters.file.local_file.LocalFileRepository.__init__","text":"Initialize the object. Creates the working directory if it doesn't exist. Source code in repository_orm/adapters/file/local_file.py def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir )","title":"__init__()"},{"location":"reference/#repository_orm.adapters.file.local_file.LocalFileRepository.delete","text":"Delete the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" )","title":"delete()"},{"location":"reference/#repository_orm.adapters.file.local_file.LocalFileRepository.load","text":"Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_","title":"load()"},{"location":"reference/#repository_orm.adapters.file.local_file.LocalFileRepository.save","text":"Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/local_file.py def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_","title":"save()"},{"location":"reference/#repository_orm.config","text":"Define the configuration of the main program.","title":"config"},{"location":"reference/#repository_orm.exceptions","text":"Store the repository-orm exceptions.","title":"exceptions"},{"location":"reference/#repository_orm.exceptions.AutoIncrementError","text":"Raised when the id_ auto increment repository feature fails. Source code in repository_orm/exceptions.py class AutoIncrementError ( Exception ): \"\"\"Raised when the id_ auto increment repository feature fails.\"\"\"","title":"AutoIncrementError"},{"location":"reference/#repository_orm.exceptions.EntityNotFoundError","text":"Raised when the search or retrieve of an entity fails. Source code in repository_orm/exceptions.py class EntityNotFoundError ( Exception ): \"\"\"Raised when the search or retrieve of an entity fails.\"\"\"","title":"EntityNotFoundError"},{"location":"reference/#repository_orm.exceptions.FileContentNotLoadedError","text":"Raised when trying to access the content of a file that has not been loaded. Source code in repository_orm/exceptions.py class FileContentNotLoadedError ( Exception ): \"\"\"Raised when trying to access the content of a file that has not been loaded.\"\"\"","title":"FileContentNotLoadedError"},{"location":"reference/#repository_orm.exceptions.TooManyEntitiesError","text":"Raised when more entities than expected where found. Source code in repository_orm/exceptions.py class TooManyEntitiesError ( Exception ): \"\"\"Raised when more entities than expected where found.\"\"\"","title":"TooManyEntitiesError"},{"location":"reference/#repository_orm.model","text":"Store the common business model of all entities.","title":"model"},{"location":"reference/#repository_orm.model.Entity","text":"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have identity equality . We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. Source code in repository_orm/model.py class Entity ( BaseModel ): \"\"\"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have *identity equality*. We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. \"\"\" id_ : EntityID = - 1 _defined_values : Dict [ str , Any ] = PrivateAttr () _skip_on_merge : List [ str ] = [] def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) @property def model_name ( self ) -> str : \"\"\"Return the entity model name.\"\"\" return self . __class__ . __name__ @property def _model_name ( self ) -> str : # pragma: nocover \"\"\"Return the entity model name.\"\"\" warnings . warn ( \"Use model_name instead before 2022-06-10\" , DeprecationWarning ) return self . model_name def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self @property def defined_values ( self ) -> Dict [ str , Any ]: \"\"\"Return the entity defined values.\"\"\" return self . _defined_values def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {}","title":"Entity"},{"location":"reference/#repository_orm.model.Entity.defined_values","text":"Return the entity defined values.","title":"defined_values"},{"location":"reference/#repository_orm.model.Entity.model_name","text":"Return the entity model name.","title":"model_name"},{"location":"reference/#repository_orm.model.Entity.__gt__","text":"Assert if an object is greater than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ )","title":"__gt__()"},{"location":"reference/#repository_orm.model.Entity.__hash__","text":"Create an unique hash of the class object. Source code in repository_orm/model.py def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" )","title":"__hash__()"},{"location":"reference/#repository_orm.model.Entity.__init__","text":"Initialize the defined values. Source code in repository_orm/model.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data","title":"__init__()"},{"location":"reference/#repository_orm.model.Entity.__lt__","text":"Assert if an object is smaller than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ )","title":"__lt__()"},{"location":"reference/#repository_orm.model.Entity.__setattr__","text":"Store the set attribute into the _defined_values. Source code in repository_orm/model.py def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value )","title":"__setattr__()"},{"location":"reference/#repository_orm.model.Entity.clear_defined_values","text":"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error Incompatible return value type (got \"Entity\", expected \"Entity\") Source code in repository_orm/model.py def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {}","title":"clear_defined_values()"},{"location":"reference/#repository_orm.model.Entity.merge","text":"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to self . Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self","title":"merge()"},{"location":"reference/#repository_orm.model.File","text":"Model a computer file. Source code in repository_orm/model.py class File ( Entity , Generic [ AnyStr ]): \"\"\"Model a computer file.\"\"\" path : str created_at : Optional [ datetime ] = None updated_at : Optional [ datetime ] = None owner : Optional [ str ] = None group : Optional [ str ] = None permissions : Optional [ str ] = None # The use of a private attribute and the impossibility of loading the content # at object creation will be fixed on Pydantic 1.9. # We will be able to define the excluded attribute content in the Config of the # model. # # For more information on how to improve this code, read this: # https://lyz-code.github.io/blue-book/coding/python/pydantic/#define-fields-to-exclude-from-exporting-at-config-level # noqa:E501 _content : Optional [ AnyStr ] = PrivateAttr ( None ) # If the content is of type bytes is_bytes : bool = False @property def basename ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . basename ( self . path ) @property def dirname ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . dirname ( self . path ) @property def extension ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return self . basename . split ( \".\" )[ - 1 ] @property def content ( self ) -> AnyStr : \"\"\"Return the content of the file. Returns: The content of the file. Raises: FileContentNotLoadedError: if the content is not yet loaded. \"\"\" if self . _content is None : raise FileContentNotLoadedError ( \"The content of the file has not been loaded yet.\" ) return self . _content","title":"File"},{"location":"reference/#repository_orm.model.File.basename","text":"Return the name of the file.","title":"basename"},{"location":"reference/#repository_orm.model.File.content","text":"Return the content of the file. Returns: Type Description ~AnyStr The content of the file. Exceptions: Type Description FileContentNotLoadedError if the content is not yet loaded.","title":"content"},{"location":"reference/#repository_orm.model.File.dirname","text":"Return the name of the file.","title":"dirname"},{"location":"reference/#repository_orm.model.File.extension","text":"Return the name of the file.","title":"extension"},{"location":"reference/#repository_orm.services","text":"Define all the orchestration functionality required by the program to work. Classes and functions that connect the different domain model objects with the adapters and handlers to achieve the program's purpose.","title":"services"},{"location":"reference/#repository_orm.services.load_file_repository","text":"Load the FileRepository object that matches the url protocol. Parameters: Name Type Description Default url str Url to connect to the storage backend. 'local:.' Returns: Type Description FileRepository[AnyStr] File Repository that understands the url protocol. Source code in repository_orm/services.py def load_file_repository ( url : str = \"local:.\" ) -> \"FileRepository[AnyStr]\" : \"\"\"Load the FileRepository object that matches the url protocol. Args: url: Url to connect to the storage backend. Returns: File Repository that understands the url protocol. \"\"\" if \"local:\" in url : return LocalFileRepository ( workdir = url . split ( \":\" )[ 1 ]) raise ValueError ( f \"File Repository URL: { url } not recognized.\" )","title":"load_file_repository()"},{"location":"reference/#repository_orm.services.load_repository","text":"Load the Repository object that matches the database url protocol. Parameters: Name Type Description Default database_url str Url to connect to the storage backend. 'fake://' Returns: Type Description Union[repository_orm.adapters.data.fake.FakeRepository, repository_orm.adapters.data.pypika.PypikaRepository, repository_orm.adapters.data.tinydb.TinyDBRepository] Repository that understands the url protocol. Source code in repository_orm/services.py def load_repository ( database_url : str = \"fake://\" , models : Optional [ Models [ Entity ]] = None , search_exception : bool = True , ) -> Repository : \"\"\"Load the Repository object that matches the database url protocol. Args: database_url: Url to connect to the storage backend. Returns: Repository that understands the url protocol. \"\"\" if \"fake://\" in database_url : return FakeRepository ( models , \"\" , search_exception ) if \"sqlite://\" in database_url : return PypikaRepository ( models , database_url , search_exception ) if \"tinydb://\" in database_url : return TinyDBRepository ( models , database_url , search_exception ) raise ValueError ( f \"Database URL: { database_url } not recognized.\" )","title":"load_repository()"},{"location":"reference/#repository_orm.version","text":"Utilities to retrieve the information of the program version.","title":"version"},{"location":"reference/#repository_orm.version.version_info","text":"Display the version of the program, python and the platform. Source code in repository_orm/version.py def version_info () -> str : \"\"\"Display the version of the program, python and the platform.\"\"\" info = { \"repository_orm version\" : __version__ , \"python version\" : sys . version . replace ( \" \\n \" , \" \" ), \"platform\" : platform . platform (), } return \" \\n \" . join ( f \" { k + ':' : >30 } { v } \" for k , v in info . items ())","title":"version_info()"},{"location":"reference_adapters/","text":"repository_orm.adapters special \u00b6 data special \u00b6 abstract \u00b6 Define the interface of the repositories. Repository ( ABC ) \u00b6 Gather common methods and define the interface of the repositories. Attributes: Name Type Description database_url URL specifying the connection to the database. Source code in repository_orm/adapters/data/abstract.py class Repository ( abc . ABC ): \"\"\"Gather common methods and define the interface of the repositories. Attributes: database_url: URL specifying the connection to the database. \"\"\" @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) @abc . abstractmethod def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. This method is specific to each database adapter. Args: entity: Entity to add to the repository. Returns: entity \"\"\" raise NotImplementedError @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity @abc . abstractmethod def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Particular implementation of the adapter. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" raise NotImplementedError def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities @abc . abstractmethod def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. \"\"\" raise NotImplementedError @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities @abc . abstractmethod def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" raise NotImplementedError @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) def _model_not_found ( self , models : OptionalModelOrModels [ Entity ], append_str : str = \"\" ) -> EntityNotFoundError : \"\"\"Raise the appropriate EntityNotFoundError exception based on models. Args: models: Type of entity object to obtain. append_str: message to append after the message of no entities found. Must start with a space Raises: EntityNotFoundError \"\"\" models = self . _build_models ( models ) entity_str = \", \" . join ([ model . __name__ for model in models ]) return EntityNotFoundError ( f \"There are no entities of type { entity_str } \" f \"in the repository { append_str } .\" ) def _build_models ( self , models : OptionalModelOrModels [ Entity ]) -> Models [ Entity ]: \"\"\"Create the Models from the OptionalModelOrModels.\"\"\" if models is None : models = self . models elif not isinstance ( models , list ): models = [ models ] return models @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None search_exception bool Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. True Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () add ( self , entities , merge = False ) \u00b6 Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If merge is True, added entities will be merged with the existent ones in the cache. Parameters: Name Type Description Default entity Entity to add to the repository. required Returns: Type Description ~EntityOrEntities entity Source code in repository_orm/adapters/data/abstract.py def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) all ( self , models = None ) \u00b6 Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Source code in repository_orm/adapters/data/abstract.py def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError first ( self , models ) \u00b6 Get the smallest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Type of entity object to obtain. required Returns: Type Description entity Smallest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover get ( self , id_ , models = None ) \u00b6 Obtain an entity from the repository by it's ID. Also save the entity in the cache Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None id_ Union[int, str, pydantic.networks.AnyHttpUrl] ID of the entity to obtain. required Returns: Type Description entity Entity object that matches the id_ Exceptions: Type Description EntityNotFoundError If the entity is not found. TooManyEntitiesError If more than one entity was found. Source code in repository_orm/adapters/data/abstract.py def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error next_id ( self , entity ) \u00b6 Return one id unit more than the last entity id in the repository index. Parameters: Name Type Description Default entity ~Entity Entity whose model we want to get the next entity id. required Source code in repository_orm/adapters/data/abstract.py def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) search ( self , fields , models = None ) \u00b6 Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None fields Dict[str, Union[int, str, pydantic.networks.AnyHttpUrl]] Dictionary with the {key}:{value} to search. required Returns: Type Description entities List of Entity object that matches the search criteria. Exceptions: Type Description EntityNotFoundError If the entities are not found. Source code in repository_orm/adapters/data/abstract.py def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities warn_on_models ( models , method ) \u00b6 Warn users that using more than one model is going to be deprecated. Source code in repository_orm/adapters/data/abstract.py def warn_on_models ( models : OptionalModelOrModels [ Entity ], method : str ) -> None : \"\"\"Warn users that using more than one model is going to be deprecated.\"\"\" if isinstance ( models , list ): warnings . warn ( f \"In 2022-06-10 using repo. { method } with a list of models is going to be \" \"deprecated, please use just one model instead\" , UserWarning , ) elif models is None : warnings . warn ( f \"In 2022-06-10 using repo. { method } without any model is going to be \" \"deprecated, please set the model you want to use.\" , UserWarning , ) cache \u00b6 Define the cache of the data repositories. Cache \u00b6 Define the cache of a repository. The entries are saved in the cache attribute under a dictionary similar to: { !!! model_1 \"{\" Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } Source code in repository_orm/adapters/data/cache.py class Cache : \"\"\"Define the cache of a repository. The entries are saved in the `cache` attribute under a dictionary similar to: { Model_1: { Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ ) __init__ ( self ) special \u00b6 Initialize the class. Source code in repository_orm/adapters/data/cache.py def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} add ( self , entity_or_entities ) \u00b6 Add an entity to the cache. Source code in repository_orm/adapters/data/cache.py def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) entity_has_not_changed ( self , entity ) \u00b6 Check if entity is equal to the version in the cache. Source code in repository_orm/adapters/data/cache.py def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False get ( self , entity ) \u00b6 Return the cached value of an entity. Source code in repository_orm/adapters/data/cache.py def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] remove ( self , entity_or_entities ) \u00b6 Remove an entity from the cache if it exists. Source code in repository_orm/adapters/data/cache.py def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ ) fake \u00b6 Store the fake repository implementation. FakeRepository ( Repository ) \u00b6 Implement the repository pattern using a memory dictionary. Source code in repository_orm/adapters/data/fake.py class FakeRepository ( Repository ): \"\"\"Implement the repository pattern using a memory dictionary.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] except KeyError : self . new_entities [ type ( entity )] = {} self . new_entities [ type ( entity )][ entity . id_ ] = entity return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): matching_entities . append ( self . entities [ model ][ id_ ]) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] . copy () if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): entities += sorted ( entity for entity_id , entity in self . entities [ model ] . items () ) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" models = self . _build_models ( models ) if len ( models ) == 1 : models = models [ 0 ] all_entities : List [ Entity ] = self . all ( models ) entities_dict = { entity . id_ : entity for entity in all_entities } entity_attributes = { entity . id_ : entity . dict () for entity in all_entities } for key , value in fields . items (): # Get entities that have the value `value` entities_with_value = entity_attributes | grep ( value , use_regexp = True , strict_checking = False ) matching_entity_attributes = {} try : entities_with_value [ \"matched_values\" ] except KeyError as error : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) from error for path in entities_with_value [ \"matched_values\" ]: entity_id = re . sub ( r \"root\\['?(.*?)'?\\]\\[.*\" , r \"\\1\" , path ) # Convert int ids from str to int try : entity_id = int ( entity_id ) except ValueError : entity_id = re . sub ( r \"'(.*)'\" , r \"\\1\" , entity_id ) # Add the entity to the matching ones only if the value is of the # attribute `key`. if re . match ( rf \"root\\['? { entity_id } '?\\]\\[' { key } '\\]\" , path ): matching_entity_attributes [ entity_id ] = extract ( entity_attributes , f \"root[ { entity_id } ]\" ) entity_attributes = matching_entity_attributes entities = [ entities_dict [ key ] for key in entity_attributes . keys ()] return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def _staged_entities ( self , models : Models [ Entity ]) -> List [ Entity ]: \"\"\"Return a list of staged entities of type models. Args: models: Return only instances of these models. \"\"\" staged_entities = [] for model in models : staged_entities += [ entity for _ , entity in self . new_entities [ model ] . items () ] return staged_entities def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Source code in repository_orm/adapters/data/fake.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/fake.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/fake.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/fake.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/fake.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/fake.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) pypika \u00b6 Define the Pypika Repository. PypikaRepository ( Repository ) \u00b6 Implement the repository pattern using the Pypika query builder. Source code in repository_orm/adapters/data/pypika.py class PypikaRepository ( Repository ): \"\"\"Implement the repository pattern using the Pypika query builder.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () def _execute ( self , query : Union [ Query , str ]) -> sqlite3 . Cursor : \"\"\"Execute an SQL statement from a Pypika query object. Args: query: Pypika query \"\"\" return self . cursor . execute ( str ( query )) @staticmethod def _table ( entity : Entity ) -> Table : \"\"\"Return the table of the selected entity object.\"\"\" return Table ( entity . model_name . lower ()) @staticmethod def _table_model ( model : Type [ Entity ]) -> Table : \"\"\"Return the table of the selected entity class.\"\"\" return Table ( model . __name__ . lower ()) def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" table = self . _table ( entity ) columns = list ( entity . dict () . keys ()) columns [ columns . index ( \"id_\" )] = \"id\" values = [ value for key , value in entity . dict () . items ()] insert_query = Query . into ( table ) . columns ( tuple ( columns )) . insert ( tuple ( values )) # Until https://github.com/kayak/pypika/issues/535 is solved we need to write # The upsert statement ourselves. # nosec: B608:hardcoded_sql_expressions, Possible SQL injection vector through # string-based query construction. We're not letting the user define the # values of the query, the only variable inputs are the keys, that are # defined by the developer, so it's not probable that he chooses an # entity attributes that are an SQL injection. Once the #535 issue is # solved, we should get rid of this error too. upsert_query = ( str ( insert_query ) + \" ON CONFLICT(id) DO UPDATE SET \" # nosec + \", \" . join ([ f \" { key } =excluded. { key } \" for key in columns ]) ) self . _execute ( upsert_query ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) . where ( table . id == id_ ) matching_entities += self . _build_entities ( model , query ) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) entities += self . _build_entities ( model , query ) return entities def _build_entities ( self , model : Type [ Entity ], query : Query ) -> List [ Entity ]: \"\"\"Build Entity objects from the data extracted from the database. Args: models: The model of the entity to build query: pypika query of the entities you want to build \"\"\" cursor = self . _execute ( query ) entities_data = cursor . fetchall () attributes = [ description [ 0 ] for description in cursor . description ] entities : List [ Entity ] = [] for entity_data in entities_data : entity_dict = { attributes [ index ]: entity_data [ index ] for index in range ( 0 , len ( entity_data )) } entity_dict [ \"id_\" ] = entity_dict . pop ( \"id\" ) entities . append ( model ( ** entity_dict )) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) for key , value in fields . items (): if key == \"id_\" : key = \"id\" if isinstance ( value , str ): query = query . where ( functions . Lower ( getattr ( table , key )) . regexp ( value . lower ()) ) else : query = query . where ( getattr ( table , key ) == value ) with suppress ( OperationalError ): entities += self . _build_entities ( model , query ) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close () __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/pypika.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/pypika.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/pypika.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close () commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/pypika.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/pypika.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) tinydb \u00b6 Define the TinyDB Repository. TinyDBRepository ( Repository ) \u00b6 Implement the repository pattern using the TinyDB. Source code in repository_orm/adapters/data/tinydb.py class TinyDBRepository ( Repository ): \"\"\"Implement the repository pattern using the TinyDB.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" self . staged [ \"add\" ] . append ( entity ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" models = self . _build_models ( models ) model_query = self . _build_model_query ( models ) matching_entities_data = self . db_ . search (( Query () . id_ == id_ ) & ( model_query )) if len ( matching_entities_data ) == 1 : return self . _build_entity ( matching_entities_data [ 0 ], models ) if len ( matching_entities_data ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _build_entity ( self , entity_data : Dict [ Any , Any ], models : OptionalModelOrModels [ Entity ] = None , ) -> Entity : \"\"\"Create an entity from the data stored in a row of the database. Args: entity_data: Dictionary with the attributes of the entity. models: Type of entity object to obtain. Returns: entity: Built Entity. \"\"\" # If we don't copy the data, the all method stop being idempotent. entity_data = entity_data . copy () model_name = entity_data . pop ( \"model_type_\" ) models = self . _build_models ( models ) for model in models : if model . schema ()[ \"title\" ] . lower () == model_name : try : return model . parse_obj ( entity_data ) except ValidationError as error : log . error ( f \"Error loading the model { model_name . capitalize () } \" f \"for the register { str ( entity_data ) } \" ) raise error # no cover: this code is going to disappear soon, it makes no sense to create # a new test raise ValueError ( f \"No model found with name { model_name } \" ) # pragma: no cover def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) if models == self . models : entities_data = self . db_ . all () else : query = self . _build_model_query ( models ) entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) return entities @staticmethod def _export_entity ( entity : Entity ) -> Dict [ Any , Any ]: \"\"\"Export the attributes of the entity appending the required by TinyDB. Args: entity: Entity to export. Returns: entity_data: Dictionary with the attributes of the entity. \"\"\" entity_data = entity . dict () entity_data [ \"model_type_\" ] = entity . model_name . lower () return entity_data def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) query = self . _build_search_query ( fields , models ) # Build entities entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def _build_search_query ( self , fields : Dict [ str , EntityID ], models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts for a repository search. Select only the models that contain the fields. If the field type is a list, change the query accordingly. Args: models: Type of entity object to obtain. fields: Dictionary with the {key}:{value} to search. Returns: Query based on the type of models and fields. \"\"\" query_parts = [] for model in models : model_query_parts = [] schema = model . schema ()[ \"properties\" ] for field , value in fields . items (): if field not in schema . keys (): continue with suppress ( KeyError ): if schema [ field ][ \"type\" ] == \"array\" : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . test ( _regexp_in_list , value )) ) continue if isinstance ( value , str ): model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . search ( value , flags = re . IGNORECASE )) ) else : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] == value ) ) if len ( model_query_parts ) != 0 : query_parts . append ( self . _merge_query ( model_query_parts , mode = \"and\" )) if len ( query_parts ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return self . _merge_query ( query_parts , mode = \"or\" ) def _build_model_query ( self , models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts from the models. Args: models: Type of entity object to obtain. Returns: List of query parts based on the type of models \"\"\" query_parts = [] for model in models : query_parts . append ( Query () . model_type_ == model . __name__ . lower ()) return self . _merge_query ( query_parts , mode = \"or\" ) @staticmethod def _merge_query ( query_parts : List [ QueryInstance ], mode : str = \"and\" ) -> QueryInstance : \"\"\"Join all the query parts into a query. Args: query_parts: List of queries to concatenate. mode: \"and\" or \"or\" for the join method. Returns: A query object that joins all parts. \"\"\" query = query_parts [ 0 ] for query_part in query_parts [ 1 :]: if mode == \"and\" : query = query & query_part else : query = query | query_part return query def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close () __init__ ( self , models = None , database_url = '' , search_exception = True ) special \u00b6 Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/tinydb.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} apply_migrations ( self , migrations_directory ) \u00b6 Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/tinydb.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError close ( self ) \u00b6 Close the connection to the database. Source code in repository_orm/adapters/data/tinydb.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close () commit ( self ) \u00b6 Persist the changes into the repository. Source code in repository_orm/adapters/data/tinydb.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () delete ( self , entity ) \u00b6 Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/tinydb.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) last ( self , models = None ) \u00b6 Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/tinydb.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) file special \u00b6 abstract \u00b6 Define the abstract interface for file repositories. FileRepository ( BaseModel , ABC , Generic ) pydantic-model \u00b6 Define the interface of the file repositories. Source code in repository_orm/adapters/file/abstract.py class FileRepository ( BaseModel , ABC , Generic [ AnyStr ]): \"\"\"Define the interface of the file repositories.\"\"\" workdir : str = \".\" @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_ delete ( self , file_ ) \u00b6 Delete the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError fix_path ( self , file_ ) \u00b6 Update the path to include the workdir. Source code in repository_orm/adapters/file/abstract.py def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_ load ( self , file_ ) \u00b6 Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError save ( self , file_ ) \u00b6 Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError local_file \u00b6 Define the local filesystem adapter. LocalFileRepository ( FileRepository ) pydantic-model \u00b6 Define the local filesystem adapter. Source code in repository_orm/adapters/file/local_file.py class LocalFileRepository ( FileRepository [ AnyStr ]): \"\"\"Define the local filesystem adapter.\"\"\" def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_ def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" ) __init__ ( self , workdir ) special \u00b6 Initialize the object. Creates the working directory if it doesn't exist. Source code in repository_orm/adapters/file/local_file.py def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) delete ( self , file_ ) \u00b6 Delete the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" ) load ( self , file_ ) \u00b6 Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ save ( self , file_ ) \u00b6 Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/local_file.py def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_","title":"Repository Implementations"},{"location":"reference_adapters/#repository_orm.adapters","text":"","title":"adapters"},{"location":"reference_adapters/#repository_orm.adapters.data","text":"","title":"data"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract","text":"Define the interface of the repositories.","title":"abstract"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository","text":"Gather common methods and define the interface of the repositories. Attributes: Name Type Description database_url URL specifying the connection to the database. Source code in repository_orm/adapters/data/abstract.py class Repository ( abc . ABC ): \"\"\"Gather common methods and define the interface of the repositories. Attributes: database_url: URL specifying the connection to the database. \"\"\" @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache () def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" ) @abc . abstractmethod def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. This method is specific to each database adapter. Args: entity: Entity to add to the repository. Returns: entity \"\"\" raise NotImplementedError @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity @abc . abstractmethod def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Particular implementation of the adapter. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" raise NotImplementedError def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities @abc . abstractmethod def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. \"\"\" raise NotImplementedError @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities @abc . abstractmethod def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Particular implementation of the database adapter. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" raise NotImplementedError @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" ) def _model_not_found ( self , models : OptionalModelOrModels [ Entity ], append_str : str = \"\" ) -> EntityNotFoundError : \"\"\"Raise the appropriate EntityNotFoundError exception based on models. Args: models: Type of entity object to obtain. append_str: message to append after the message of no entities found. Must start with a space Raises: EntityNotFoundError \"\"\" models = self . _build_models ( models ) entity_str = \", \" . join ([ model . __name__ for model in models ]) return EntityNotFoundError ( f \"There are no entities of type { entity_str } \" f \"in the repository { append_str } .\" ) def _build_models ( self , models : OptionalModelOrModels [ Entity ]) -> Models [ Entity ]: \"\"\"Create the Models from the OptionalModelOrModels.\"\"\" if models is None : models = self . models elif not isinstance ( models , list ): models = [ models ] return models @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError","title":"Repository"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None search_exception bool Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. True Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. search_exception: Raise an exception when search doesn't return any value. It's a migration flag used to test the behaviour from 2022-06-10 onwards. \"\"\" self . database_url = database_url self . search_exception = search_exception if models is None : models = [] else : warnings . warn ( \"In 2022-06-10 initializing the repository with any model is going \" \"to be deprecated, please remove the models argument.\" , UserWarning , ) self . models = models self . cache = Cache ()","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.add","text":"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If merge is True, added entities will be merged with the existent ones in the cache. Parameters: Name Type Description Default entity Entity to add to the repository. required Returns: Type Description ~EntityOrEntities entity Source code in repository_orm/adapters/data/abstract.py def add ( self , entities : EntityOrEntities , merge : bool = False ) -> EntityOrEntities : \"\"\"Append an entity or list of entities to the repository. If the id is not set, it will automatically increment the last available one. If `merge` is True, added entities will be merged with the existent ones in the cache. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if isinstance ( entities , EntityModel ): entity = entities if isinstance ( entity . id_ , int ) and entity . id_ < 0 : entity . id_ = self . next_id ( entity ) if merge : with suppress ( EntityNotFoundError ): stored_entity = self . get ( entity . id_ , type ( entity )) entity = stored_entity . merge ( entity ) if self . cache . entity_has_not_changed ( entity ): log . debug ( f \"Skipping the addition of entity { entity } as it hasn't changed\" ) return entity entity = self . _add ( entity ) self . cache . add ( entity ) return entity if isinstance ( entities , list ): updated_entities : List [ EntityModel ] = [] for entity in entities : updated_entities . append ( self . add ( entity , merge )) return updated_entities raise ValueError ( \"Please add an entity or a list of entities\" )","title":"add()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.all","text":"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Source code in repository_orm/adapters/data/abstract.py def all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Also store the entities in the cache. Args: models: Entity class or classes to obtain. \"\"\" warn_on_models ( models , \"all\" ) entities = sorted ( self . _all ( models )) for entity in entities : entity . clear_defined_values () self . cache . add ( entity ) return entities","title":"all()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError","title":"apply_migrations()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" raise NotImplementedError","title":"close()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" raise NotImplementedError","title":"commit()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/abstract.py @abc . abstractmethod def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" raise NotImplementedError","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.first","text":"Get the smallest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Type of entity object to obtain. required Returns: Type Description entity Smallest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def first ( self , models : OptionalModelOrModels [ Entity ]) -> Entity : \"\"\"Get the smallest entity from the repository. Args: models: Type of entity object to obtain. Returns: entity: Smallest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"first\" ) try : return min ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) # pragma: nocover raise self . _model_not_found ( models ) from error # pragma: nocover","title":"first()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.get","text":"Obtain an entity from the repository by it's ID. Also save the entity in the cache Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None id_ Union[int, str, pydantic.networks.AnyHttpUrl] ID of the entity to obtain. required Returns: Type Description entity Entity object that matches the id_ Exceptions: Type Description EntityNotFoundError If the entity is not found. TooManyEntitiesError If more than one entity was found. Source code in repository_orm/adapters/data/abstract.py def get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Also save the entity in the cache Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" warn_on_models ( models , \"get\" ) entity = self . _get ( id_ , models ) entity . clear_defined_values () self . cache . add ( entity ) return entity","title":"get()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/abstract.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) try : return max ( self . all ( models )) except ValueError as error : models = self . _build_models ( models ) raise self . _model_not_found ( models ) from error","title":"last()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.next_id","text":"Return one id unit more than the last entity id in the repository index. Parameters: Name Type Description Default entity ~Entity Entity whose model we want to get the next entity id. required Source code in repository_orm/adapters/data/abstract.py def next_id ( self , entity : Entity ) -> int : \"\"\"Return one id unit more than the last entity id in the repository index. Args: entity: Entity whose model we want to get the next entity id. \"\"\" try : last_id = self . last ( type ( entity )) . id_ except EntityNotFoundError : return 0 if isinstance ( last_id , int ): return last_id + 1 raise AutoIncrementError ( \"Auto increment is not yet supported for Entities with string id_s. \" \"Please set the id_ yourself before adding the entities to the \" \"repository.\" )","title":"next_id()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.Repository.search","text":"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None fields Dict[str, Union[int, str, pydantic.networks.AnyHttpUrl]] Dictionary with the {key}:{value} to search. required Returns: Type Description entities List of Entity object that matches the search criteria. Exceptions: Type Description EntityNotFoundError If the entities are not found. Source code in repository_orm/adapters/data/abstract.py def search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Also add the found entities to the cache. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" warn_on_models ( models , \"search\" ) try : found_entities = sorted ( self . _search ( fields , models )) except EntityNotFoundError as error : if self . search_exception : warnings . warn ( \"From 2022-06-10 when repo.search doesn't find any result it will \" \"return an empty list instead of raising an EntityNotFoundError \" \"exception. To use this behaviour initialize your repository with \" \"search_exception=False.\" , UserWarning , ) raise error found_entities = [] for entity in found_entities : entity . clear_defined_values () self . cache . add ( entity ) return found_entities","title":"search()"},{"location":"reference_adapters/#repository_orm.adapters.data.abstract.warn_on_models","text":"Warn users that using more than one model is going to be deprecated. Source code in repository_orm/adapters/data/abstract.py def warn_on_models ( models : OptionalModelOrModels [ Entity ], method : str ) -> None : \"\"\"Warn users that using more than one model is going to be deprecated.\"\"\" if isinstance ( models , list ): warnings . warn ( f \"In 2022-06-10 using repo. { method } with a list of models is going to be \" \"deprecated, please use just one model instead\" , UserWarning , ) elif models is None : warnings . warn ( f \"In 2022-06-10 using repo. { method } without any model is going to be \" \"deprecated, please set the model you want to use.\" , UserWarning , )","title":"warn_on_models()"},{"location":"reference_adapters/#repository_orm.adapters.data.cache","text":"Define the cache of the data repositories.","title":"cache"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache","text":"Define the cache of a repository. The entries are saved in the cache attribute under a dictionary similar to: { !!! model_1 \"{\" Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } Source code in repository_orm/adapters/data/cache.py class Cache : \"\"\"Define the cache of a repository. The entries are saved in the `cache` attribute under a dictionary similar to: { Model_1: { Entity_1_ID: Entity_1, Entity_2_ID: Entity_2, }, } \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {} def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ()) def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ] def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ )","title":"Cache"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache.__init__","text":"Initialize the class. Source code in repository_orm/adapters/data/cache.py def __init__ ( self ) -> None : \"\"\"Initialize the class.\"\"\" self . cache : Dict [ Type [ EntityModel ], CacheEntry [ Any ]] = {}","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache.add","text":"Add an entity to the cache. Source code in repository_orm/adapters/data/cache.py def add ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Add an entity to the cache.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : self . cache . setdefault ( type ( entity ), {}) self . cache [ type ( entity )] . setdefault ( entity . id_ , entity . copy ())","title":"add()"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache.entity_has_not_changed","text":"Check if entity is equal to the version in the cache. Source code in repository_orm/adapters/data/cache.py def entity_has_not_changed ( self , entity : Entity ) -> bool : \"\"\"Check if entity is equal to the version in the cache.\"\"\" try : if self . get ( entity ) == entity : return True except KeyError : return False return False","title":"entity_has_not_changed()"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache.get","text":"Return the cached value of an entity. Source code in repository_orm/adapters/data/cache.py def get ( self , entity : Entity ) -> Entity : \"\"\"Return the cached value of an entity.\"\"\" return self . cache [ type ( entity )][ entity . id_ ]","title":"get()"},{"location":"reference_adapters/#repository_orm.adapters.data.cache.Cache.remove","text":"Remove an entity from the cache if it exists. Source code in repository_orm/adapters/data/cache.py def remove ( self , entity_or_entities : EntityOrEntities ) -> None : \"\"\"Remove an entity from the cache if it exists.\"\"\" if isinstance ( entity_or_entities , EntityModel ): entities = [ entity_or_entities ] else : entities = list ( entity_or_entities ) for entity in entities : with suppress ( KeyError ): self . cache [ type ( entity )] . pop ( entity . id_ )","title":"remove()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake","text":"Store the fake repository implementation.","title":"fake"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository","text":"Implement the repository pattern using a memory dictionary. Source code in repository_orm/adapters/data/fake.py class FakeRepository ( Repository ): \"\"\"Implement the repository pattern using a memory dictionary.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. Args: entity: Entity to add to the repository. Returns: entity \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] except KeyError : self . new_entities [ type ( entity )] = {} self . new_entities [ type ( entity )][ entity . id_ ] = entity return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): matching_entities . append ( self . entities [ model ][ id_ ]) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] . copy () if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : with suppress ( KeyError ): entities += sorted ( entity for entity_id , entity in self . entities [ model ] . items () ) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {} def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" models = self . _build_models ( models ) if len ( models ) == 1 : models = models [ 0 ] all_entities : List [ Entity ] = self . all ( models ) entities_dict = { entity . id_ : entity for entity in all_entities } entity_attributes = { entity . id_ : entity . dict () for entity in all_entities } for key , value in fields . items (): # Get entities that have the value `value` entities_with_value = entity_attributes | grep ( value , use_regexp = True , strict_checking = False ) matching_entity_attributes = {} try : entities_with_value [ \"matched_values\" ] except KeyError as error : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) from error for path in entities_with_value [ \"matched_values\" ]: entity_id = re . sub ( r \"root\\['?(.*?)'?\\]\\[.*\" , r \"\\1\" , path ) # Convert int ids from str to int try : entity_id = int ( entity_id ) except ValueError : entity_id = re . sub ( r \"'(.*)'\" , r \"\\1\" , entity_id ) # Add the entity to the matching ones only if the value is of the # attribute `key`. if re . match ( rf \"root\\['? { entity_id } '?\\]\\[' { key } '\\]\" , path ): matching_entity_attributes [ entity_id ] = extract ( entity_attributes , f \"root[ { entity_id } ]\" ) entity_attributes = matching_entity_attributes entities = [ entities_dict [ key ] for key in entity_attributes . keys ()] return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def _staged_entities ( self , models : Models [ Entity ]) -> List [ Entity ]: \"\"\"Return a list of staged entities of type models. Args: models: Return only instances of these models. \"\"\" staged_entities = [] for model in models : staged_entities += [ entity for _ , entity in self . new_entities [ model ] . items () ] return staged_entities def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True","title":"FakeRepository"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.__init__","text":"Initialize the repository attributes. Source code in repository_orm/adapters/data/fake.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes.\"\"\" super () . __init__ ( models = models , search_exception = search_exception ) if database_url == \"/inexistent_dir/database.db\" : raise ConnectionError ( f \"Could not create database file: { database_url } \" ) self . entities : FakeRepositoryDB [ Entity ] = {} self . new_entities : FakeRepositoryDB [ Entity ] = {} self . is_connection_closed = False","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/fake.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" # The fake repository doesn't have any schema","title":"apply_migrations()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/fake.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . is_connection_closed = True","title":"close()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/fake.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for model , entities in self . new_entities . items (): self . entities [ model ] = entities self . new_entities = {}","title":"commit()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/fake.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" if self . new_entities == {}: self . new_entities = copy . deepcopy ( self . entities . copy ()) try : self . new_entities [ type ( entity )] . pop ( entity . id_ , None ) except KeyError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.data.fake.FakeRepository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/fake.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" try : last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : models = self . _build_models ( models ) try : # Empty repo but entities staged to be commited. return max ( self . _staged_entities ( models )) except KeyError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : models = self . _build_models ( models ) last_staged_entity : Entity = max ( self . _staged_entities ( models )) except KeyError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ])","title":"last()"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika","text":"Define the Pypika Repository.","title":"pypika"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository","text":"Implement the repository pattern using the Pypika query builder. Source code in repository_orm/adapters/data/pypika.py class PypikaRepository ( Repository ): \"\"\"Implement the repository pattern using the Pypika query builder.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor () def _execute ( self , query : Union [ Query , str ]) -> sqlite3 . Cursor : \"\"\"Execute an SQL statement from a Pypika query object. Args: query: Pypika query \"\"\" return self . cursor . execute ( str ( query )) @staticmethod def _table ( entity : Entity ) -> Table : \"\"\"Return the table of the selected entity object.\"\"\" return Table ( entity . model_name . lower ()) @staticmethod def _table_model ( model : Type [ Entity ]) -> Table : \"\"\"Return the table of the selected entity class.\"\"\" return Table ( model . __name__ . lower ()) def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" table = self . _table ( entity ) columns = list ( entity . dict () . keys ()) columns [ columns . index ( \"id_\" )] = \"id\" values = [ value for key , value in entity . dict () . items ()] insert_query = Query . into ( table ) . columns ( tuple ( columns )) . insert ( tuple ( values )) # Until https://github.com/kayak/pypika/issues/535 is solved we need to write # The upsert statement ourselves. # nosec: B608:hardcoded_sql_expressions, Possible SQL injection vector through # string-based query construction. We're not letting the user define the # values of the query, the only variable inputs are the keys, that are # defined by the developer, so it's not probable that he chooses an # entity attributes that are an SQL injection. Once the #535 issue is # solved, we should get rid of this error too. upsert_query = ( str ( insert_query ) + \" ON CONFLICT(id) DO UPDATE SET \" # nosec + \", \" . join ([ f \" { key } =excluded. { key } \" for key in columns ]) ) self . _execute ( upsert_query ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" matching_entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) . where ( table . id == id_ ) matching_entities += self . _build_entities ( model , query ) if len ( matching_entities ) == 1 : return matching_entities [ 0 ] if len ( matching_entities ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) entities += self . _build_entities ( model , query ) return entities def _build_entities ( self , model : Type [ Entity ], query : Query ) -> List [ Entity ]: \"\"\"Build Entity objects from the data extracted from the database. Args: models: The model of the entity to build query: pypika query of the entities you want to build \"\"\" cursor = self . _execute ( query ) entities_data = cursor . fetchall () attributes = [ description [ 0 ] for description in cursor . description ] entities : List [ Entity ] = [] for entity_data in entities_data : entity_dict = { attributes [ index ]: entity_data [ index ] for index in range ( 0 , len ( entity_data )) } entity_dict [ \"id_\" ] = entity_dict . pop ( \"id\" ) entities . append ( model ( ** entity_dict )) return entities def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) for model in models : table = self . _table_model ( model ) query = Query . from_ ( table ) . select ( \"*\" ) for key , value in fields . items (): if key == \"id_\" : key = \"id\" if isinstance ( value , str ): query = query . where ( functions . Lower ( getattr ( table , key )) . regexp ( value . lower ()) ) else : query = query . where ( getattr ( table , key ) == value ) with suppress ( OperationalError ): entities += self . _build_entities ( model , query ) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" ) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close ()","title":"PypikaRepository"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/pypika.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) database_file = database_url . replace ( \"sqlite:///\" , \"\" ) if not os . path . isfile ( database_file ): try : with open ( database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { database_file } \" ) from error self . connection = sqlite3 . connect ( database_file ) self . connection . create_function ( \"REGEXP\" , 2 , _regexp ) self . cursor = self . connection . cursor ()","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/pypika.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" backend = get_backend ( self . database_url ) migrations = read_migrations ( migrations_directory ) with backend . lock (): log . info ( \"Running database migrations\" ) try : backend . apply_migrations ( backend . to_apply ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error running database migrations\" ) log . error ( error ) log . debug ( \"Rolling back the database migrations\" ) try : backend . rollback_migrations ( backend . to_rollback ( migrations )) except Exception as error : # noqa: W0703 # We need to add tests for this function and use a less generic # exception log . error ( \"Error rolling back database migrations\" ) log . error ( error ) raise error log . debug ( \"Complete running database migrations\" )","title":"apply_migrations()"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/pypika.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . connection . close ()","title":"close()"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/pypika.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" self . connection . commit ()","title":"commit()"},{"location":"reference_adapters/#repository_orm.adapters.data.pypika.PypikaRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Exceptions: Type Description EntityNotFoundError If the entity is not found. Source code in repository_orm/adapters/data/pypika.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. Raises: EntityNotFoundError: If the entity is not found. \"\"\" table = self . _table ( entity ) try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error query = Query . from_ ( table ) . delete () . where ( table . id == entity . id_ ) self . _execute ( query )","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb","text":"Define the TinyDB Repository.","title":"tinydb"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository","text":"Implement the repository pattern using the TinyDB. Source code in repository_orm/adapters/data/tinydb.py class TinyDBRepository ( Repository ): \"\"\"Implement the repository pattern using the TinyDB.\"\"\" def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []} def _add ( self , entity : Entity ) -> Entity : \"\"\"Append an entity to the repository. If the id is not set, autoincrement the last. Args: entity: Entity to add to the repository. Returns: entity \"\"\" self . staged [ \"add\" ] . append ( entity ) return entity def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity ) def _get ( self , id_ : EntityID , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Obtain an entity from the repository by it's ID. Args: models: Entity class or classes to obtain. id_: ID of the entity to obtain. Returns: entity: Entity object that matches the id_ Raises: EntityNotFoundError: If the entity is not found. TooManyEntitiesError: If more than one entity was found. \"\"\" models = self . _build_models ( models ) model_query = self . _build_model_query ( models ) matching_entities_data = self . db_ . search (( Query () . id_ == id_ ) & ( model_query )) if len ( matching_entities_data ) == 1 : return self . _build_entity ( matching_entities_data [ 0 ], models ) if len ( matching_entities_data ) == 0 : raise self . _model_not_found ( models , f \" with id { id_ } \" ) raise TooManyEntitiesError ( f \"More than one entity was found with the id { id_ } \" ) def _build_entity ( self , entity_data : Dict [ Any , Any ], models : OptionalModelOrModels [ Entity ] = None , ) -> Entity : \"\"\"Create an entity from the data stored in a row of the database. Args: entity_data: Dictionary with the attributes of the entity. models: Type of entity object to obtain. Returns: entity: Built Entity. \"\"\" # If we don't copy the data, the all method stop being idempotent. entity_data = entity_data . copy () model_name = entity_data . pop ( \"model_type_\" ) models = self . _build_models ( models ) for model in models : if model . schema ()[ \"title\" ] . lower () == model_name : try : return model . parse_obj ( entity_data ) except ValidationError as error : log . error ( f \"Error loading the model { model_name . capitalize () } \" f \"for the register { str ( entity_data ) } \" ) raise error # no cover: this code is going to disappear soon, it makes no sense to create # a new test raise ValueError ( f \"No model found with name { model_name } \" ) # pragma: no cover def _all ( self , models : OptionalModelOrModels [ Entity ] = None ) -> List [ Entity ]: \"\"\"Get all the entities from the repository whose class is included in models. Args: models: Entity class or classes to obtain. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) if models == self . models : entities_data = self . db_ . all () else : query = self . _build_model_query ( models ) entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) return entities @staticmethod def _export_entity ( entity : Entity ) -> Dict [ Any , Any ]: \"\"\"Export the attributes of the entity appending the required by TinyDB. Args: entity: Entity to export. Returns: entity_data: Dictionary with the attributes of the entity. \"\"\" entity_data = entity . dict () entity_data [ \"model_type_\" ] = entity . model_name . lower () return entity_data def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear () def _search ( self , fields : Dict [ str , EntityID ], models : OptionalModelOrModels [ Entity ] = None , ) -> List [ Entity ]: \"\"\"Get the entities whose attributes match one or several conditions. Args: models: Entity class or classes to obtain. fields: Dictionary with the {key}:{value} to search. Returns: entities: List of Entity object that matches the search criteria. Raises: EntityNotFoundError: If the entities are not found. \"\"\" entities : List [ Entity ] = [] models = self . _build_models ( models ) query = self . _build_search_query ( fields , models ) # Build entities entities_data = self . db_ . search ( query ) for entity_data in entities_data : entities . append ( self . _build_entity ( entity_data , models )) if len ( entities ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return entities def _build_search_query ( self , fields : Dict [ str , EntityID ], models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts for a repository search. Select only the models that contain the fields. If the field type is a list, change the query accordingly. Args: models: Type of entity object to obtain. fields: Dictionary with the {key}:{value} to search. Returns: Query based on the type of models and fields. \"\"\" query_parts = [] for model in models : model_query_parts = [] schema = model . schema ()[ \"properties\" ] for field , value in fields . items (): if field not in schema . keys (): continue with suppress ( KeyError ): if schema [ field ][ \"type\" ] == \"array\" : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . test ( _regexp_in_list , value )) ) continue if isinstance ( value , str ): model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] . search ( value , flags = re . IGNORECASE )) ) else : model_query_parts . append ( ( Query () . model_type_ == model . __name__ . lower ()) & ( Query ()[ field ] == value ) ) if len ( model_query_parts ) != 0 : query_parts . append ( self . _merge_query ( model_query_parts , mode = \"and\" )) if len ( query_parts ) == 0 : raise self . _model_not_found ( models , f \" that match the search filter { fields } \" ) return self . _merge_query ( query_parts , mode = \"or\" ) def _build_model_query ( self , models : Models [ Entity ], ) -> QueryInstance : \"\"\"Build the Query parts from the models. Args: models: Type of entity object to obtain. Returns: List of query parts based on the type of models \"\"\" query_parts = [] for model in models : query_parts . append ( Query () . model_type_ == model . __name__ . lower ()) return self . _merge_query ( query_parts , mode = \"or\" ) @staticmethod def _merge_query ( query_parts : List [ QueryInstance ], mode : str = \"and\" ) -> QueryInstance : \"\"\"Join all the query parts into a query. Args: query_parts: List of queries to concatenate. mode: \"and\" or \"or\" for the join method. Returns: A query object that joins all parts. \"\"\" query = query_parts [ 0 ] for query_part in query_parts [ 1 :]: if mode == \"and\" : query = query & query_part else : query = query | query_part return query def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ]) def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close ()","title":"TinyDBRepository"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.__init__","text":"Initialize the repository attributes. Parameters: Name Type Description Default database_url str URL specifying the connection to the database. '' models Optional[List[Type[~Entity]]] List of stored entity models. None Source code in repository_orm/adapters/data/tinydb.py def __init__ ( self , models : OptionalModels [ Entity ] = None , database_url : str = \"\" , search_exception : bool = True , ) -> None : \"\"\"Initialize the repository attributes. Args: database_url: URL specifying the connection to the database. models: List of stored entity models. \"\"\" super () . __init__ ( models , database_url , search_exception ) self . database_file = os . path . expanduser ( database_url . replace ( \"tinydb://\" , \"\" )) if not os . path . isfile ( self . database_file ): try : with open ( self . database_file , \"a\" , encoding = \"utf-8\" ) as file_cursor : file_cursor . close () except FileNotFoundError as error : raise ConnectionError ( f \"Could not create the database file: { self . database_file } \" ) from error serialization = SerializationMiddleware ( JSONStorage ) serialization . register_serializer ( DateTimeSerializer (), \"TinyDate\" ) self . db_ = TinyDB ( self . database_file , storage = serialization , sort_keys = True , indent = 4 ) self . staged : Dict [ str , List [ Any ]] = { \"add\" : [], \"remove\" : []}","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.apply_migrations","text":"Run the migrations of the repository schema. Parameters: Name Type Description Default migrations_directory str path to the directory containing the migration scripts. required Source code in repository_orm/adapters/data/tinydb.py def apply_migrations ( self , migrations_directory : str ) -> None : \"\"\"Run the migrations of the repository schema. Args: migrations_directory: path to the directory containing the migration scripts. \"\"\" raise NotImplementedError","title":"apply_migrations()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.close","text":"Close the connection to the database. Source code in repository_orm/adapters/data/tinydb.py def close ( self ) -> None : \"\"\"Close the connection to the database.\"\"\" self . db_ . close ()","title":"close()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.commit","text":"Persist the changes into the repository. Source code in repository_orm/adapters/data/tinydb.py def commit ( self ) -> None : \"\"\"Persist the changes into the repository.\"\"\" for entity in self . staged [ \"add\" ]: self . db_ . upsert ( self . _export_entity ( entity ), ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ), ) self . staged [ \"add\" ] . clear () for entity in self . staged [ \"remove\" ]: self . db_ . remove ( ( Query () . model_type_ == entity . model_name . lower ()) & ( Query () . id_ == entity . id_ ) ) self . staged [ \"remove\" ] . clear ()","title":"commit()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.delete","text":"Delete an entity from the repository. Parameters: Name Type Description Default entity ~Entity Entity to remove from the repository. required Source code in repository_orm/adapters/data/tinydb.py def delete ( self , entity : Entity ) -> None : \"\"\"Delete an entity from the repository. Args: entity: Entity to remove from the repository. \"\"\" try : self . get ( entity . id_ , type ( entity )) except EntityNotFoundError as error : raise EntityNotFoundError ( f \"Unable to delete entity { entity } because it's not in the repository\" ) from error self . staged [ \"remove\" ] . append ( entity )","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.data.tinydb.TinyDBRepository.last","text":"Get the biggest entity from the repository. Parameters: Name Type Description Default models Union[Type[~Entity], List[Type[~Entity]]] Entity class or classes to obtain. None Returns: Type Description entity Biggest Entity object of type models. Exceptions: Type Description EntityNotFoundError If there are no entities. Source code in repository_orm/adapters/data/tinydb.py def last ( self , models : OptionalModelOrModels [ Entity ] = None ) -> Entity : \"\"\"Get the biggest entity from the repository. Args: models: Entity class or classes to obtain. Returns: entity: Biggest Entity object of type models. Raises: EntityNotFoundError: If there are no entities. \"\"\" warn_on_models ( models , \"last\" ) models = self . _build_models ( models ) try : with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , message = \"In 2022-06-10.*list of models\" ) last_index_entity : Entity = super () . last ( models ) except EntityNotFoundError as empty_repo : try : # Empty repo but entities staged to be commited. return max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError as no_staged_entities : # Empty repo and no entities staged. raise empty_repo from no_staged_entities try : last_staged_entity = max ( entity for entity in self . staged [ \"add\" ] if entity . __class__ in models ) except ValueError : # Full repo and no staged entities. return last_index_entity # Full repo and staged entities. return max ([ last_index_entity , last_staged_entity ])","title":"last()"},{"location":"reference_adapters/#repository_orm.adapters.file","text":"","title":"file"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract","text":"Define the abstract interface for file repositories.","title":"abstract"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract.FileRepository","text":"Define the interface of the file repositories. Source code in repository_orm/adapters/file/abstract.py class FileRepository ( BaseModel , ABC , Generic [ AnyStr ]): \"\"\"Define the interface of the file repositories.\"\"\" workdir : str = \".\" @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_","title":"FileRepository"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract.FileRepository.delete","text":"Delete the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def delete ( self , file_ : \"File[AnyStr]\" ) -> None : \"\"\"Delete the file from the persistence system.\"\"\" raise NotImplementedError","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract.FileRepository.fix_path","text":"Update the path to include the workdir. Source code in repository_orm/adapters/file/abstract.py def fix_path ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Update the path to include the workdir.\"\"\" if self . workdir not in file_ . path : file_ . path = f \" { self . workdir } / { file_ . path } \" return file_","title":"fix_path()"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract.FileRepository.load","text":"Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def load ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Load the content of the file from the persistence system.\"\"\" raise NotImplementedError","title":"load()"},{"location":"reference_adapters/#repository_orm.adapters.file.abstract.FileRepository.save","text":"Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/abstract.py @abstractmethod def save ( self , file_ : \"File[AnyStr]\" ) -> \"File[AnyStr]\" : \"\"\"Save the content of the file into the persistence system.\"\"\" raise NotImplementedError","title":"save()"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file","text":"Define the local filesystem adapter.","title":"local_file"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file.LocalFileRepository","text":"Define the local filesystem adapter. Source code in repository_orm/adapters/file/local_file.py class LocalFileRepository ( FileRepository [ AnyStr ]): \"\"\"Define the local filesystem adapter.\"\"\" def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir ) def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_ def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_ def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" )","title":"LocalFileRepository"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file.LocalFileRepository.__init__","text":"Initialize the object. Creates the working directory if it doesn't exist. Source code in repository_orm/adapters/file/local_file.py def __init__ ( self , workdir : str ) -> None : \"\"\"Initialize the object. Creates the working directory if it doesn't exist. \"\"\" if not os . path . exists ( workdir ): os . makedirs ( workdir ) super () . __init__ ( workdir = workdir )","title":"__init__()"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file.LocalFileRepository.delete","text":"Delete the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def delete ( self , file_ : File [ AnyStr ]) -> None : \"\"\"Delete the file from the persistence system.\"\"\" log . debug ( f \"Deleting the content of file { file_ . path } \" ) try : os . remove ( os . path . expanduser ( file_ . path )) except FileNotFoundError : log . warning ( f \"Can't remove the file { file_ . path } as it doesn't exist \" \"in the file repository.\" )","title":"delete()"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file.LocalFileRepository.load","text":"Load the content of the file from the persistence system. Source code in repository_orm/adapters/file/local_file.py def load ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Load the content of the file from the persistence system.\"\"\" log . debug ( f \"Loading content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"rb\" encoding = None else : mode = \"r\" encoding = \"utf-8\" with open ( os . path . expanduser ( file_ . path ), mode , encoding = encoding ) as file_descriptor : # W0212: Access to private attribute, but it's managed by us so it's OK file_ . _content = file_descriptor . read () # noqa: W0212 return file_","title":"load()"},{"location":"reference_adapters/#repository_orm.adapters.file.local_file.LocalFileRepository.save","text":"Save the content of the file into the persistence system. Source code in repository_orm/adapters/file/local_file.py def save ( self , file_ : File [ AnyStr ]) -> File [ AnyStr ]: \"\"\"Save the content of the file into the persistence system.\"\"\" log . debug ( f \"Saving the content of file { file_ . path } \" ) file_ = self . fix_path ( file_ ) if file_ . is_bytes : mode = \"wb+\" else : mode = \"w+\" with open ( os . path . expanduser ( file_ . path ), mode ) as file_descriptor : file_descriptor . write ( file_ . content ) return file_","title":"save()"},{"location":"reference_exceptions/","text":"repository_orm.exceptions \u00b6 Store the repository-orm exceptions. AutoIncrementError ( Exception ) \u00b6 Raised when the id_ auto increment repository feature fails. Source code in repository_orm/exceptions.py class AutoIncrementError ( Exception ): \"\"\"Raised when the id_ auto increment repository feature fails.\"\"\" EntityNotFoundError ( Exception ) \u00b6 Raised when the search or retrieve of an entity fails. Source code in repository_orm/exceptions.py class EntityNotFoundError ( Exception ): \"\"\"Raised when the search or retrieve of an entity fails.\"\"\" FileContentNotLoadedError ( Exception ) \u00b6 Raised when trying to access the content of a file that has not been loaded. Source code in repository_orm/exceptions.py class FileContentNotLoadedError ( Exception ): \"\"\"Raised when trying to access the content of a file that has not been loaded.\"\"\" TooManyEntitiesError ( Exception ) \u00b6 Raised when more entities than expected where found. Source code in repository_orm/exceptions.py class TooManyEntitiesError ( Exception ): \"\"\"Raised when more entities than expected where found.\"\"\"","title":"Exceptions"},{"location":"reference_exceptions/#repository_orm.exceptions","text":"Store the repository-orm exceptions.","title":"exceptions"},{"location":"reference_exceptions/#repository_orm.exceptions.AutoIncrementError","text":"Raised when the id_ auto increment repository feature fails. Source code in repository_orm/exceptions.py class AutoIncrementError ( Exception ): \"\"\"Raised when the id_ auto increment repository feature fails.\"\"\"","title":"AutoIncrementError"},{"location":"reference_exceptions/#repository_orm.exceptions.EntityNotFoundError","text":"Raised when the search or retrieve of an entity fails. Source code in repository_orm/exceptions.py class EntityNotFoundError ( Exception ): \"\"\"Raised when the search or retrieve of an entity fails.\"\"\"","title":"EntityNotFoundError"},{"location":"reference_exceptions/#repository_orm.exceptions.FileContentNotLoadedError","text":"Raised when trying to access the content of a file that has not been loaded. Source code in repository_orm/exceptions.py class FileContentNotLoadedError ( Exception ): \"\"\"Raised when trying to access the content of a file that has not been loaded.\"\"\"","title":"FileContentNotLoadedError"},{"location":"reference_exceptions/#repository_orm.exceptions.TooManyEntitiesError","text":"Raised when more entities than expected where found. Source code in repository_orm/exceptions.py class TooManyEntitiesError ( Exception ): \"\"\"Raised when more entities than expected where found.\"\"\"","title":"TooManyEntitiesError"},{"location":"reference_models/","text":"repository_orm.model \u00b6 Store the common business model of all entities. Entity ( BaseModel ) pydantic-model \u00b6 Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have identity equality . We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. Source code in repository_orm/model.py class Entity ( BaseModel ): \"\"\"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have *identity equality*. We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. \"\"\" id_ : EntityID = - 1 _defined_values : Dict [ str , Any ] = PrivateAttr () _skip_on_merge : List [ str ] = [] def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) @property def model_name ( self ) -> str : \"\"\"Return the entity model name.\"\"\" return self . __class__ . __name__ @property def _model_name ( self ) -> str : # pragma: nocover \"\"\"Return the entity model name.\"\"\" warnings . warn ( \"Use model_name instead before 2022-06-10\" , DeprecationWarning ) return self . model_name def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self @property def defined_values ( self ) -> Dict [ str , Any ]: \"\"\"Return the entity defined values.\"\"\" return self . _defined_values def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {} defined_values : Dict [ str , Any ] property readonly \u00b6 Return the entity defined values. model_name : str property readonly \u00b6 Return the entity model name. __gt__ ( self , other ) special \u00b6 Assert if an object is greater than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) __hash__ ( self ) special \u00b6 Create an unique hash of the class object. Source code in repository_orm/model.py def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) __init__ ( self , ** data ) special \u00b6 Initialize the defined values. Source code in repository_orm/model.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data __lt__ ( self , other ) special \u00b6 Assert if an object is smaller than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) __setattr__ ( self , attribute , value ) special \u00b6 Store the set attribute into the _defined_values. Source code in repository_orm/model.py def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) clear_defined_values ( self ) \u00b6 Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error Incompatible return value type (got \"Entity\", expected \"Entity\") Source code in repository_orm/model.py def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {} merge ( self , other ) \u00b6 Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to self . Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self File ( Entity , Generic ) pydantic-model \u00b6 Model a computer file. Source code in repository_orm/model.py class File ( Entity , Generic [ AnyStr ]): \"\"\"Model a computer file.\"\"\" path : str created_at : Optional [ datetime ] = None updated_at : Optional [ datetime ] = None owner : Optional [ str ] = None group : Optional [ str ] = None permissions : Optional [ str ] = None # The use of a private attribute and the impossibility of loading the content # at object creation will be fixed on Pydantic 1.9. # We will be able to define the excluded attribute content in the Config of the # model. # # For more information on how to improve this code, read this: # https://lyz-code.github.io/blue-book/coding/python/pydantic/#define-fields-to-exclude-from-exporting-at-config-level # noqa:E501 _content : Optional [ AnyStr ] = PrivateAttr ( None ) # If the content is of type bytes is_bytes : bool = False @property def basename ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . basename ( self . path ) @property def dirname ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . dirname ( self . path ) @property def extension ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return self . basename . split ( \".\" )[ - 1 ] @property def content ( self ) -> AnyStr : \"\"\"Return the content of the file. Returns: The content of the file. Raises: FileContentNotLoadedError: if the content is not yet loaded. \"\"\" if self . _content is None : raise FileContentNotLoadedError ( \"The content of the file has not been loaded yet.\" ) return self . _content basename : str property readonly \u00b6 Return the name of the file. content : ~ AnyStr property readonly \u00b6 Return the content of the file. Returns: Type Description ~AnyStr The content of the file. Exceptions: Type Description FileContentNotLoadedError if the content is not yet loaded. dirname : str property readonly \u00b6 Return the name of the file. extension : str property readonly \u00b6 Return the name of the file.","title":"Models"},{"location":"reference_models/#repository_orm.model","text":"Store the common business model of all entities.","title":"model"},{"location":"reference_models/#repository_orm.model.Entity","text":"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have identity equality . We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. Source code in repository_orm/model.py class Entity ( BaseModel ): \"\"\"Model of any object no defined by it's attributes whom instead has an identity. Unlike value objects, they have *identity equality*. We can change their values, and they are still recognizably the same thing. An entity with a negative id means that the id needs to be set by the repository. The _defined_values are used to know which attributes were set by the user at the time of merging objects. \"\"\" id_ : EntityID = - 1 _defined_values : Dict [ str , Any ] = PrivateAttr () _skip_on_merge : List [ str ] = [] def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ ) def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ ) def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" ) def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value ) @property def model_name ( self ) -> str : \"\"\"Return the entity model name.\"\"\" return self . __class__ . __name__ @property def _model_name ( self ) -> str : # pragma: nocover \"\"\"Return the entity model name.\"\"\" warnings . warn ( \"Use model_name instead before 2022-06-10\" , DeprecationWarning ) return self . model_name def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self @property def defined_values ( self ) -> Dict [ str , Any ]: \"\"\"Return the entity defined values.\"\"\" return self . _defined_values def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {}","title":"Entity"},{"location":"reference_models/#repository_orm.model.Entity.defined_values","text":"Return the entity defined values.","title":"defined_values"},{"location":"reference_models/#repository_orm.model.Entity.model_name","text":"Return the entity model name.","title":"model_name"},{"location":"reference_models/#repository_orm.model.Entity.__gt__","text":"Assert if an object is greater than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __gt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is greater than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ > other . id_ return str ( self . id_ ) > str ( other . id_ )","title":"__gt__()"},{"location":"reference_models/#repository_orm.model.Entity.__hash__","text":"Create an unique hash of the class object. Source code in repository_orm/model.py def __hash__ ( self ) -> int : \"\"\"Create an unique hash of the class object.\"\"\" return hash ( f \" { self . model_name } - { self . id_ } \" )","title":"__hash__()"},{"location":"reference_models/#repository_orm.model.Entity.__init__","text":"Initialize the defined values. Source code in repository_orm/model.py def __init__ ( self , ** data : Any ) -> None : \"\"\"Initialize the defined values.\"\"\" super () . __init__ ( ** data ) self . _defined_values = data","title":"__init__()"},{"location":"reference_models/#repository_orm.model.Entity.__lt__","text":"Assert if an object is smaller than us. Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def __lt__ ( self , other : \"Entity\" ) -> bool : \"\"\"Assert if an object is smaller than us. Args: other: Entity to compare. \"\"\" if isinstance ( other . id_ , int ) and isinstance ( self . id_ , int ): return self . id_ < other . id_ return str ( self . id_ ) < str ( other . id_ )","title":"__lt__()"},{"location":"reference_models/#repository_orm.model.Entity.__setattr__","text":"Store the set attribute into the _defined_values. Source code in repository_orm/model.py def __setattr__ ( self , attribute : str , value : Any ) -> None : \"\"\"Store the set attribute into the _defined_values.\"\"\" if attribute != \"_defined_values\" : self . _defined_values [ attribute ] = value super () . __setattr__ ( attribute , value )","title":"__setattr__()"},{"location":"reference_models/#repository_orm.model.Entity.clear_defined_values","text":"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error Incompatible return value type (got \"Entity\", expected \"Entity\") Source code in repository_orm/model.py def clear_defined_values ( self ) -> None : \"\"\"Remove all references to defined values. I tried to return self so that it can be used chained with repo.get(), but I get a mypy error `Incompatible return value type (got \"Entity\", expected \"Entity\")` \"\"\" self . _defined_values = {}","title":"clear_defined_values()"},{"location":"reference_models/#repository_orm.model.Entity.merge","text":"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to self . Parameters: Name Type Description Default other Entity Entity to compare. required Source code in repository_orm/model.py def merge ( self , other : \"Entity\" ) -> \"Entity\" : \"\"\"Update the attributes with the ones manually set by the user of other. If the other object has default values not set by the user, they won't be propagated to `self`. Args: other: Entity to compare. \"\"\" if not isinstance ( other , type ( self )): raise ValueError ( \"Can't merge objects of different models \" f \"( { self . model_name } with { other . model_name } ).\" ) if self . id_ != other . id_ : raise ValueError ( f \"Can't merge two { self . model_name } s with different ids\" ) # Merge objects # W0212: access to an internal property, but it's managed by us so there is # no problem on it. for attribute , value in other . _defined_values . items (): # noqa: W0212 if attribute not in self . _skip_on_merge : setattr ( self , attribute , value ) return self","title":"merge()"},{"location":"reference_models/#repository_orm.model.File","text":"Model a computer file. Source code in repository_orm/model.py class File ( Entity , Generic [ AnyStr ]): \"\"\"Model a computer file.\"\"\" path : str created_at : Optional [ datetime ] = None updated_at : Optional [ datetime ] = None owner : Optional [ str ] = None group : Optional [ str ] = None permissions : Optional [ str ] = None # The use of a private attribute and the impossibility of loading the content # at object creation will be fixed on Pydantic 1.9. # We will be able to define the excluded attribute content in the Config of the # model. # # For more information on how to improve this code, read this: # https://lyz-code.github.io/blue-book/coding/python/pydantic/#define-fields-to-exclude-from-exporting-at-config-level # noqa:E501 _content : Optional [ AnyStr ] = PrivateAttr ( None ) # If the content is of type bytes is_bytes : bool = False @property def basename ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . basename ( self . path ) @property def dirname ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return os . path . dirname ( self . path ) @property def extension ( self ) -> str : \"\"\"Return the name of the file.\"\"\" return self . basename . split ( \".\" )[ - 1 ] @property def content ( self ) -> AnyStr : \"\"\"Return the content of the file. Returns: The content of the file. Raises: FileContentNotLoadedError: if the content is not yet loaded. \"\"\" if self . _content is None : raise FileContentNotLoadedError ( \"The content of the file has not been loaded yet.\" ) return self . _content","title":"File"},{"location":"reference_models/#repository_orm.model.File.basename","text":"Return the name of the file.","title":"basename"},{"location":"reference_models/#repository_orm.model.File.content","text":"Return the content of the file. Returns: Type Description ~AnyStr The content of the file. Exceptions: Type Description FileContentNotLoadedError if the content is not yet loaded.","title":"content"},{"location":"reference_models/#repository_orm.model.File.dirname","text":"Return the name of the file.","title":"dirname"},{"location":"reference_models/#repository_orm.model.File.extension","text":"Return the name of the file.","title":"extension"},{"location":"repositories/","text":"Data repositories give a common interface to store the models in databases. Usage \u00b6 The different repositories share the next operations: add Add an Entity object or list of Entity objects to the repository, if it already exist, it updates the stored attributes. If you want to merge the entities before adding them to the repository, use the merge=True argument. delete Remove an Entity object form the repository. get Obtain an Entity from the repository by it's ID. commit Persist the changes into the repository. all Get all the entities of a type or types from the repository. If no argument is given, it will return all entities. search Get the entities whose attributes match a condition or regular expression. first Get the first entity of a type or types of the repository. If no argument is given, it will return the first of any type of entity. last Get the last entity of a type or types of the repository. If no argument is given, it will return the first of any type of entity. apply_migrations Run the migrations of the repository schema. close Close the connection to the database. Changes in the repository aren't persisted until you run repo.commit() . Repositories \u00b6 To change the repository you only need to change the url passed to load_repository . We have the next repositories: FakeRepository : is the simplest implementation of the repository pattern, meant to be used for the tests and early phases of development. TinyDBRepository : is the implementation of the repository pattern for the local NoSQL TinyDB database. You can use it in the early stages of the project where the data schema is yet unstable and you don't have enough entities to have performance issues. PypikaRepository : is the implementation of the repository pattern for the relational databases. It's meant for the stages of the project where the schema is more stable and you need the improved performance of these types of databases.","title":"Repositories"},{"location":"repositories/#usage","text":"The different repositories share the next operations: add Add an Entity object or list of Entity objects to the repository, if it already exist, it updates the stored attributes. If you want to merge the entities before adding them to the repository, use the merge=True argument. delete Remove an Entity object form the repository. get Obtain an Entity from the repository by it's ID. commit Persist the changes into the repository. all Get all the entities of a type or types from the repository. If no argument is given, it will return all entities. search Get the entities whose attributes match a condition or regular expression. first Get the first entity of a type or types of the repository. If no argument is given, it will return the first of any type of entity. last Get the last entity of a type or types of the repository. If no argument is given, it will return the first of any type of entity. apply_migrations Run the migrations of the repository schema. close Close the connection to the database. Changes in the repository aren't persisted until you run repo.commit() .","title":"Usage"},{"location":"repositories/#repositories","text":"To change the repository you only need to change the url passed to load_repository . We have the next repositories: FakeRepository : is the simplest implementation of the repository pattern, meant to be used for the tests and early phases of development. TinyDBRepository : is the implementation of the repository pattern for the local NoSQL TinyDB database. You can use it in the early stages of the project where the data schema is yet unstable and you don't have enough entities to have performance issues. PypikaRepository : is the implementation of the repository pattern for the relational databases. It's meant for the stages of the project where the schema is more stable and you need the improved performance of these types of databases.","title":"Repositories"},{"location":"testing/","text":"Testing your code is a hated but good practice. Repository ORM tries to make your testing experience less cumbersome. You can use different strategies depending on the level of testing. For unit and integration tests the FakeRepository may be your best option, for end-to-end ones, I'd use TinyDBRepository . Unit and integration tests \u00b6 Unit tests are meant to test individual units of code, for example, a function or a method of a class. You'll probably use them to test your models or services . import pytest from repository_orm import Entity , FakeRepository , Repository @pytest . fixture () def repo () -> FakeRepository : return FakeRepository () class Author ( Entity ): first_name : str def create_greeting ( repo : Repository , author_id : int ) -> str : author = repo . get ( author_id , Author ) return f \"Hi { author . first_name } !\" def test_greetings ( repo : FakeRepository ) -> None : author = Author ( id_ = 20 , first_name = \"Brandon\" ) repo . add ( author ) repo . commit () result = create_greeting ( repo , 20 ) assert result == \"Hi Brandon!\" # noqa End-to-end tests \u00b6 End-to-end tests evaluate the whole functionality of the program from the eyes of the user. For example, testing a command line or the API endpoint. Usually the program loads the repository from storage at start time, which means that the FakeRepository can't be used. We're going to create a click command line program called greet that once it's called, it will return the first author in the repository. It's a little bit more complex but bare with me. from typing import Generator import click import pytest from click.testing import CliRunner from py._path.local import LocalPath from repository_orm import Entity , Repository , TinyDBRepository , load_repository # Model class Author ( Entity ): first_name : str # Fixtures @pytest . fixture ( name = \"db_tinydb\" ) def db_tinydb_ ( tmpdir : LocalPath ) -> str : tinydb_file_path = str ( tmpdir . join ( \"tinydb.db\" )) return f \"tinydb:/// { tinydb_file_path } \" @pytest . fixture () def repo ( db_tinydb : str ) -> Generator [ TinyDBRepository , None , None ]: repo = TinyDBRepository ( database_url = db_tinydb ) yield repo repo . close () # Service def create_greeting ( repo : Repository ) -> str : first_author = repo . all ( Author )[ 0 ] return f \"Hi { first_author . first_name } , you're the first author!\" # Entrypoint @click . command () @click . argument ( \"database_url\" ) def greet ( database_url : str ) -> None : repo = load_repository ( database_url ) print ( create_greeting ( repo )) repo . close () # Test def test_greetings ( repo : TinyDBRepository , db_tinydb : str ) -> None : author = Author ( id_ = 20 , first_name = \"Brandon\" ) repo . add ( author ) repo . commit () runner = CliRunner () result = runner . invoke ( greet , [ db_tinydb ]) assert result . exit_code == 0 assert result . output == \"Hi Brandon, you're the first author! \\n \" # noqa First we define the fixtures, we start with db_tinydb that uses the pytest's tmpdir fixture to create a random temporal directory and then sets the database url. The repo fixture uses that database url to create a TinyDBRepository instance. The model Author and service create_greeting are similar to the previous section. The entrypoint is where we define the command line interface, in this case the command is going to be called greet and it's going to accept an argument called database_url , it will initialize the repository and use the create_greeting to show the message to the user through the terminal. To test this code, we first need to add an Author, so the function can look for it. We do it in the first three lines of test_greetings . Then we initialize the runner which simulates a command line call, and we make sure that the program exited well, and gave the output we expected.","title":"Testing"},{"location":"testing/#unit-and-integration-tests","text":"Unit tests are meant to test individual units of code, for example, a function or a method of a class. You'll probably use them to test your models or services . import pytest from repository_orm import Entity , FakeRepository , Repository @pytest . fixture () def repo () -> FakeRepository : return FakeRepository () class Author ( Entity ): first_name : str def create_greeting ( repo : Repository , author_id : int ) -> str : author = repo . get ( author_id , Author ) return f \"Hi { author . first_name } !\" def test_greetings ( repo : FakeRepository ) -> None : author = Author ( id_ = 20 , first_name = \"Brandon\" ) repo . add ( author ) repo . commit () result = create_greeting ( repo , 20 ) assert result == \"Hi Brandon!\" # noqa","title":"Unit and integration tests"},{"location":"testing/#end-to-end-tests","text":"End-to-end tests evaluate the whole functionality of the program from the eyes of the user. For example, testing a command line or the API endpoint. Usually the program loads the repository from storage at start time, which means that the FakeRepository can't be used. We're going to create a click command line program called greet that once it's called, it will return the first author in the repository. It's a little bit more complex but bare with me. from typing import Generator import click import pytest from click.testing import CliRunner from py._path.local import LocalPath from repository_orm import Entity , Repository , TinyDBRepository , load_repository # Model class Author ( Entity ): first_name : str # Fixtures @pytest . fixture ( name = \"db_tinydb\" ) def db_tinydb_ ( tmpdir : LocalPath ) -> str : tinydb_file_path = str ( tmpdir . join ( \"tinydb.db\" )) return f \"tinydb:/// { tinydb_file_path } \" @pytest . fixture () def repo ( db_tinydb : str ) -> Generator [ TinyDBRepository , None , None ]: repo = TinyDBRepository ( database_url = db_tinydb ) yield repo repo . close () # Service def create_greeting ( repo : Repository ) -> str : first_author = repo . all ( Author )[ 0 ] return f \"Hi { first_author . first_name } , you're the first author!\" # Entrypoint @click . command () @click . argument ( \"database_url\" ) def greet ( database_url : str ) -> None : repo = load_repository ( database_url ) print ( create_greeting ( repo )) repo . close () # Test def test_greetings ( repo : TinyDBRepository , db_tinydb : str ) -> None : author = Author ( id_ = 20 , first_name = \"Brandon\" ) repo . add ( author ) repo . commit () runner = CliRunner () result = runner . invoke ( greet , [ db_tinydb ]) assert result . exit_code == 0 assert result . output == \"Hi Brandon, you're the first author! \\n \" # noqa First we define the fixtures, we start with db_tinydb that uses the pytest's tmpdir fixture to create a random temporal directory and then sets the database url. The repo fixture uses that database url to create a TinyDBRepository instance. The model Author and service create_greeting are similar to the previous section. The entrypoint is where we define the command line interface, in this case the command is going to be called greet and it's going to accept an argument called database_url , it will initialize the repository and use the create_greeting to show the message to the user through the terminal. To test this code, we first need to add an Author, so the function can look for it. We do it in the first three lines of test_greetings . Then we initialize the runner which simulates a command line call, and we make sure that the program exited well, and gave the output we expected.","title":"End-to-end tests"},{"location":"tinydb_repository/","text":"The TinyDBRepository is the implementation of the repository pattern for the local NoSQL TinyDB database. You can use it in the early stages of the project where the data schema is yet unstable and you don't have enough entities to have performance issues. It stores the persisted Entities into a json file. Load it with: from repository_orm import load_repository repo = load_repository ( 'tinydb://path/to/database.db' ) Features \u00b6 Follow the overview example to see how to use each method. add Appends the Entity object to the default table by translating its attributes to a valid json row. If it already exists, it uses the upsert statement to update it's attributes in the table. delete Deletes the Entity object from the collection by searching the row that matches the object ID. get Obtain an Entity by extracting the row that matches the ID and build the Entity object with that data. commit Persist the changes into the database. all Obtain all the entities of type Entity . Similar to the get method but for all entities. search Obtain the entities whose attributes match one or multiple conditions. We create a query with all the desired criteria and then build the entities with the obtained data. apply_migrations We don't yet support migrations on the schema , so the models should be flexible enough to absorb the changes, or you can code your migrations in your program, or even better, help us solve #27 . Internal workings \u00b6 This section is meant for the people that you to expand the functionality of the TinyDBRepository. It explains how it works under the hood. Once the object is initialized with the database url with the format tinydb:///path_to_database_file , an TinyDB object is created in the db_ attribute, the path to the database is saved in database_file and a empty dictionary of staged changes is created in staged . Saving entities \u00b6 All entities are saved in the same default table _default , to avoid id_ collision, before storing the objects, an model_type_ attribute is appended with the lowercase name of the entity class. When retrieving objects with get and all , the attribute is deleted. Committing \u00b6 TinyDB doesn't have the concept of transactions, the tinyrecord plugin does, but you need to run everything in the same context manager, which doesn't suit our case. So whenever we add or remove an entity from the repository, they are stored in the staged attribute, and once commit is called, they are persisted into the database. References \u00b6 TinyDB documentation","title":"TinyDBRepository"},{"location":"tinydb_repository/#features","text":"Follow the overview example to see how to use each method. add Appends the Entity object to the default table by translating its attributes to a valid json row. If it already exists, it uses the upsert statement to update it's attributes in the table. delete Deletes the Entity object from the collection by searching the row that matches the object ID. get Obtain an Entity by extracting the row that matches the ID and build the Entity object with that data. commit Persist the changes into the database. all Obtain all the entities of type Entity . Similar to the get method but for all entities. search Obtain the entities whose attributes match one or multiple conditions. We create a query with all the desired criteria and then build the entities with the obtained data. apply_migrations We don't yet support migrations on the schema , so the models should be flexible enough to absorb the changes, or you can code your migrations in your program, or even better, help us solve #27 .","title":"Features"},{"location":"tinydb_repository/#internal-workings","text":"This section is meant for the people that you to expand the functionality of the TinyDBRepository. It explains how it works under the hood. Once the object is initialized with the database url with the format tinydb:///path_to_database_file , an TinyDB object is created in the db_ attribute, the path to the database is saved in database_file and a empty dictionary of staged changes is created in staged .","title":"Internal workings"},{"location":"tinydb_repository/#saving-entities","text":"All entities are saved in the same default table _default , to avoid id_ collision, before storing the objects, an model_type_ attribute is appended with the lowercase name of the entity class. When retrieving objects with get and all , the attribute is deleted.","title":"Saving entities"},{"location":"tinydb_repository/#committing","text":"TinyDB doesn't have the concept of transactions, the tinyrecord plugin does, but you need to run everything in the same context manager, which doesn't suit our case. So whenever we add or remove an entity from the repository, they are stored in the staged attribute, and once commit is called, they are persisted into the database.","title":"Committing"},{"location":"tinydb_repository/#references","text":"TinyDB documentation","title":"References"},{"location":"adr/001-entity_id_definition/","text":"Status \u00b6 Superseeded It has been partially superseeded by 002 String ids are again supported. Context \u00b6 Right now the Entity class has a mandatory id_ attribute of types str or int . That prevents the user to create entities a model level as they are not aware of the existent entities in the repository. Proposals \u00b6 We can: Assume that the model functions that create the new entities receive the new entity id as an argument. Change the definition of the id_ attribute so that it can be set by the repository at the moment of adding it to the repository. I've started using the first in pydo and found it cumbersome. The first approximation for the second can be to assume that the id_ is an integer, by default is set to a negative value, marking it as invalid, and when the repository sees it, gets the last id and increments it in a unit. This can't be easily done if the id_ is a str . So I'm temporarily dropping support for this types of IDs. If anyone needs them, we can create a workaround like converting them to an ascii integer and increasing it by one. If we want more complex objects to be used as ids, we may think of letting the user specify a callable to increase the ids. Decision \u00b6 We're setting a default id_ value of -1 on Entities, the repository will react to these ids, getting the last valid ID and increasing it by one. Consequences \u00b6 As a side effect, we're temporarily dropping support for str id_ attributes.","title":"Status"},{"location":"adr/001-entity_id_definition/#status","text":"Superseeded It has been partially superseeded by 002 String ids are again supported.","title":"Status"},{"location":"adr/001-entity_id_definition/#context","text":"Right now the Entity class has a mandatory id_ attribute of types str or int . That prevents the user to create entities a model level as they are not aware of the existent entities in the repository.","title":"Context"},{"location":"adr/001-entity_id_definition/#proposals","text":"We can: Assume that the model functions that create the new entities receive the new entity id as an argument. Change the definition of the id_ attribute so that it can be set by the repository at the moment of adding it to the repository. I've started using the first in pydo and found it cumbersome. The first approximation for the second can be to assume that the id_ is an integer, by default is set to a negative value, marking it as invalid, and when the repository sees it, gets the last id and increments it in a unit. This can't be easily done if the id_ is a str . So I'm temporarily dropping support for this types of IDs. If anyone needs them, we can create a workaround like converting them to an ascii integer and increasing it by one. If we want more complex objects to be used as ids, we may think of letting the user specify a callable to increase the ids.","title":"Proposals"},{"location":"adr/001-entity_id_definition/#decision","text":"We're setting a default id_ value of -1 on Entities, the repository will react to these ids, getting the last valid ID and increasing it by one.","title":"Decision"},{"location":"adr/001-entity_id_definition/#consequences","text":"As a side effect, we're temporarily dropping support for str id_ attributes.","title":"Consequences"},{"location":"adr/002-support-string-ids/","text":"Status \u00b6 Accepted Context \u00b6 In version 0.3.0 we dropped support for string ids, and that was a bad decision, as there are already projects that use it. The reason of deprecation was because the new feature to auto increment the ID of the entities that hadn't set it, wasn't \"easy\" to implement for strings. Proposals \u00b6 Restore the support for string ids, but without the auto increment feature. If you're using string ids is probably because you have an id generator or you're getting them from outside sources. Decision \u00b6 Consequences \u00b6","title":"Status"},{"location":"adr/002-support-string-ids/#status","text":"Accepted","title":"Status"},{"location":"adr/002-support-string-ids/#context","text":"In version 0.3.0 we dropped support for string ids, and that was a bad decision, as there are already projects that use it. The reason of deprecation was because the new feature to auto increment the ID of the entities that hadn't set it, wasn't \"easy\" to implement for strings.","title":"Context"},{"location":"adr/002-support-string-ids/#proposals","text":"Restore the support for string ids, but without the auto increment feature. If you're using string ids is probably because you have an id generator or you're getting them from outside sources.","title":"Proposals"},{"location":"adr/002-support-string-ids/#decision","text":"","title":"Decision"},{"location":"adr/002-support-string-ids/#consequences","text":"","title":"Consequences"},{"location":"adr/003-make_entity_models_optional_arguments/","text":"Status \u00b6 Accepted Context \u00b6 Some applications need to do operations on all or a subset of entity types in the repository, for example for the get , search , all , first or last . Right now the entity_model is a mandatory argument for these methods, that means that the code calling the repository needs to be aware of all the entity models inside the repository and call the methods for each of them. Proposals \u00b6 To solve it, we should change the entity_model an argument to a more flexible type Union[Type[Entity], List[Type[Entity]], None] . That change carries some side effects: We need to add logic at repository level to process one, a subset or all the entity types. Some repositories (tinydb and pypika) used the entity_model to build the entity, if it's not specified, we need to build the logic that lets them build the entities from their data. The calls to the methods without specifying the entity_model can have a worse performance. Build the Entities from their data \u00b6 To build the entities from the data we need those methods to be able to link that data to a model type, we can either: Delegate that functionality to the application using the repository. Configure the repositories in a way that we can deduce the model from the data stored in itself. The first solution means that each application will need to implement and maintain that code, which will lead to more maintenance and duplicated code, but a simpler repository configuration. The second solution will mean that the code for the methods is more complex and/or the repository initialization needs more arguments. We already store the key information that tells which model does the data belong to. In the tinydb repo it's stored as an attribute _model_type , and in the pypika repo is stored as tables names. The fake repo doesn't have this problem. If we initialize the repository with a models optional argument, with a list of the entity models, we can create an internal models attribute that holds a dictionary with the key equal to the value stored in the repos, and the value the model type. If the user doesn't provide this argument at repo initialization, it will be supposed that it will give the entity_model on each of the repo methods that require it, otherwise an error will be shown. Performance loss \u00b6 The entity_model acted as a filter on the amount of data to perform the operations, if the user doesn't specify it, the repo needs to work with more data and therefore be slower. Maybe some of the methods like all , first , or last will work faster on some repositories based on how they or their libraries work, but the get and search will definitely go slower. In the case of get we can mitigate it with an optional callable argument that can run regexps on the id to select the subset of entity models that contain id's of that type. Decision \u00b6 Change the signatures of the get , search , all , first and last methods to accept one, many or no Entity subclasses. If none is given, it will assume that the repository was initialized with the models argument, where the user gives the repo the model of the data it holds. For the sake of cleanness, we're renaming entity_models for models in the function arguments. Consequences \u00b6 The change makes the library more usable while it retains the performance of the previous code base. Two breaking changes were introduced though: The argument entity_model is no longer the first one for the methods get and search , but the second. The argument database_url is no longer the first argument in the load_repository function, but the second, being the first the models .","title":"Status"},{"location":"adr/003-make_entity_models_optional_arguments/#status","text":"Accepted","title":"Status"},{"location":"adr/003-make_entity_models_optional_arguments/#context","text":"Some applications need to do operations on all or a subset of entity types in the repository, for example for the get , search , all , first or last . Right now the entity_model is a mandatory argument for these methods, that means that the code calling the repository needs to be aware of all the entity models inside the repository and call the methods for each of them.","title":"Context"},{"location":"adr/003-make_entity_models_optional_arguments/#proposals","text":"To solve it, we should change the entity_model an argument to a more flexible type Union[Type[Entity], List[Type[Entity]], None] . That change carries some side effects: We need to add logic at repository level to process one, a subset or all the entity types. Some repositories (tinydb and pypika) used the entity_model to build the entity, if it's not specified, we need to build the logic that lets them build the entities from their data. The calls to the methods without specifying the entity_model can have a worse performance.","title":"Proposals"},{"location":"adr/003-make_entity_models_optional_arguments/#build-the-entities-from-their-data","text":"To build the entities from the data we need those methods to be able to link that data to a model type, we can either: Delegate that functionality to the application using the repository. Configure the repositories in a way that we can deduce the model from the data stored in itself. The first solution means that each application will need to implement and maintain that code, which will lead to more maintenance and duplicated code, but a simpler repository configuration. The second solution will mean that the code for the methods is more complex and/or the repository initialization needs more arguments. We already store the key information that tells which model does the data belong to. In the tinydb repo it's stored as an attribute _model_type , and in the pypika repo is stored as tables names. The fake repo doesn't have this problem. If we initialize the repository with a models optional argument, with a list of the entity models, we can create an internal models attribute that holds a dictionary with the key equal to the value stored in the repos, and the value the model type. If the user doesn't provide this argument at repo initialization, it will be supposed that it will give the entity_model on each of the repo methods that require it, otherwise an error will be shown.","title":"Build the Entities from their data"},{"location":"adr/003-make_entity_models_optional_arguments/#performance-loss","text":"The entity_model acted as a filter on the amount of data to perform the operations, if the user doesn't specify it, the repo needs to work with more data and therefore be slower. Maybe some of the methods like all , first , or last will work faster on some repositories based on how they or their libraries work, but the get and search will definitely go slower. In the case of get we can mitigate it with an optional callable argument that can run regexps on the id to select the subset of entity models that contain id's of that type.","title":"Performance loss"},{"location":"adr/003-make_entity_models_optional_arguments/#decision","text":"Change the signatures of the get , search , all , first and last methods to accept one, many or no Entity subclasses. If none is given, it will assume that the repository was initialized with the models argument, where the user gives the repo the model of the data it holds. For the sake of cleanness, we're renaming entity_models for models in the function arguments.","title":"Decision"},{"location":"adr/003-make_entity_models_optional_arguments/#consequences","text":"The change makes the library more usable while it retains the performance of the previous code base. Two breaking changes were introduced though: The argument entity_model is no longer the first one for the methods get and search , but the second. The argument database_url is no longer the first argument in the load_repository function, but the second, being the first the models .","title":"Consequences"},{"location":"adr/004-add_complex_queries/","text":"Status \u00b6 Draft Context \u00b6 Right now the search method only allows a dictionary of keys that the objects must match, this way of selecting objects has become insufficient for the programs that use the library forcing them to extract from the repository a greater subset of objects that contain a serie of attributes and then do another filtering afterwards. This is the case for example when the user wants to select objects that: Have a datetime or integer greater or smaller than an amount. Don't have an attribute with a defined value Match a combination of criteria, for example: Have an attribute with a value and another that is greater than X Have an attribute with a value and another that doesn't contain the value Y. Match a criteria on a related object ( JOIN operations). This schema has the next disadvantages: The user is constrained to a very basic query type The repository returns more objects than the user needs, so more traffic is sent between the application and the database The user needs to do an extra filter afterwards. This is a bad idea because doing the filtering at databases level probably gives better performance and the user needs to write more code than necessary. Proposals \u00b6 Change the way we let the user specify the criteria that it wants to search so that it can do more powerful searches. I can think of two ways of doing this: Writing the query in a string and parsing it afterwards. Writing the query with a query builder. Given this analysis , the query builder system looks better. Query builder \u00b6 We will create a Query object that follows the theory of query builders . Right now queries make sense only to extract data from the database, so speaking in SQL terms, only SELECT and DELETE queries are interesting for us. To do a select query you need: The table to extract data from The fields to extract The condition to select the rows The sorting method of the results The number of results to return All of the Query methods return self in order to be able to construct it with chained methods and properties. Those methods that don't need an argument will be coded as properties to save keystrokes on unneeded () . Table to extract data from \u00b6 Applied to the repository_orm usage, the FROM is defined by the model class both to extract the table name, build the end objects and let the type checker know what type of objects it's returning, so we need to pass the class of the model to the search and all methods. It makes sense then to pass the argument at initialization time of the Query object. Fields to extract \u00b6 In our case it doesn't make sense to let the user select the fields it wants to extract, as we return built objects and not just the values of the rows. Condition to select the objects \u00b6 Simple query operators \u00b6 Assuming that query = Query(Model) there are the next methods to select the data, it will return the objects if: equal : Attribute match value. not_equal : Attribute doesn't match value. greater : Attribute is greater than value. greater_or_equal : Attribute is greater or equal than value. smaller : Attribute is smaller than value. smaller_or_equal : Attribute is smaller or equal than value. To act on one attribute and one value you can use query.method(attribute, value) , for example query.equal('id_', 3) . To act on many attributes you can use query.method({attribute1: value1, attribute2: value2}) , for example query.greater({'rating': 3, 'created_at': datetime.datetime.now()}) . Query composition \u00b6 If you concatenate methods and properties on a query they are supposed to be conditions that all objects must match. OR \u00b6 or can be used to match one or many conditions but not others. You have to select two types of criteria, so you need to Query objects. query.greater('rating', 3).or(Query().smaller('rating', 1)) Note that if the second Query isn't initialized with a model, it will be assumed to be the same as the first one. AND \u00b6 and can be used if you want to select different criteria for different objects: Query ( Book ) . greater ( 'rating' , 3 ) . and ( Query ( Author ) . equal ( 'id_' , 1 )) Join \u00b6 join can be used to match entities if an entity that is related to them matches one or many condition, for example to get all the books of the author whose id is 1 you can: Query ( Book ) . join ( Query ( Author ) . equal ( 'id_' , 1 )) Sorting the results \u00b6 By default the results are sorted by id_ increasingly, to sort by other criteria use the sort method. query . sort ( 'rating' ) To reverse the order of the sorting use the reverse argument: query . sort ( 'rating' , reverse = True ) To order by many criteria chain sort methods, for example if you want to sort by rating and then by created_date you can use: query . sort ( 'rating' ) . sort ( 'created_date' ) Number of results \u00b6 By default all results are returned, if you want to receive only a limited amount use the limit method query . limit ( 10 ) Delete queries \u00b6 Right now the delete method allows only one or many entities, we can change the signature so that it also allows a Query object that can tweak the delete query instead of just using the id_ . Decision \u00b6 Implement the proposed solution, adding a UserWarning on the old method until we deprecate it. Consequences \u00b6 Pros: We'll improve a lot the extraction of information from the repo Cons: Users will need to change their code: How they query the repositories.","title":"Status"},{"location":"adr/004-add_complex_queries/#status","text":"Draft","title":"Status"},{"location":"adr/004-add_complex_queries/#context","text":"Right now the search method only allows a dictionary of keys that the objects must match, this way of selecting objects has become insufficient for the programs that use the library forcing them to extract from the repository a greater subset of objects that contain a serie of attributes and then do another filtering afterwards. This is the case for example when the user wants to select objects that: Have a datetime or integer greater or smaller than an amount. Don't have an attribute with a defined value Match a combination of criteria, for example: Have an attribute with a value and another that is greater than X Have an attribute with a value and another that doesn't contain the value Y. Match a criteria on a related object ( JOIN operations). This schema has the next disadvantages: The user is constrained to a very basic query type The repository returns more objects than the user needs, so more traffic is sent between the application and the database The user needs to do an extra filter afterwards. This is a bad idea because doing the filtering at databases level probably gives better performance and the user needs to write more code than necessary.","title":"Context"},{"location":"adr/004-add_complex_queries/#proposals","text":"Change the way we let the user specify the criteria that it wants to search so that it can do more powerful searches. I can think of two ways of doing this: Writing the query in a string and parsing it afterwards. Writing the query with a query builder. Given this analysis , the query builder system looks better.","title":"Proposals"},{"location":"adr/004-add_complex_queries/#query-builder","text":"We will create a Query object that follows the theory of query builders . Right now queries make sense only to extract data from the database, so speaking in SQL terms, only SELECT and DELETE queries are interesting for us. To do a select query you need: The table to extract data from The fields to extract The condition to select the rows The sorting method of the results The number of results to return All of the Query methods return self in order to be able to construct it with chained methods and properties. Those methods that don't need an argument will be coded as properties to save keystrokes on unneeded () .","title":"Query builder"},{"location":"adr/004-add_complex_queries/#table-to-extract-data-from","text":"Applied to the repository_orm usage, the FROM is defined by the model class both to extract the table name, build the end objects and let the type checker know what type of objects it's returning, so we need to pass the class of the model to the search and all methods. It makes sense then to pass the argument at initialization time of the Query object.","title":"Table to extract data from"},{"location":"adr/004-add_complex_queries/#fields-to-extract","text":"In our case it doesn't make sense to let the user select the fields it wants to extract, as we return built objects and not just the values of the rows.","title":"Fields to extract"},{"location":"adr/004-add_complex_queries/#condition-to-select-the-objects","text":"","title":"Condition to select the objects"},{"location":"adr/004-add_complex_queries/#simple-query-operators","text":"Assuming that query = Query(Model) there are the next methods to select the data, it will return the objects if: equal : Attribute match value. not_equal : Attribute doesn't match value. greater : Attribute is greater than value. greater_or_equal : Attribute is greater or equal than value. smaller : Attribute is smaller than value. smaller_or_equal : Attribute is smaller or equal than value. To act on one attribute and one value you can use query.method(attribute, value) , for example query.equal('id_', 3) . To act on many attributes you can use query.method({attribute1: value1, attribute2: value2}) , for example query.greater({'rating': 3, 'created_at': datetime.datetime.now()}) .","title":"Simple query operators"},{"location":"adr/004-add_complex_queries/#query-composition","text":"If you concatenate methods and properties on a query they are supposed to be conditions that all objects must match.","title":"Query composition"},{"location":"adr/004-add_complex_queries/#or","text":"or can be used to match one or many conditions but not others. You have to select two types of criteria, so you need to Query objects. query.greater('rating', 3).or(Query().smaller('rating', 1)) Note that if the second Query isn't initialized with a model, it will be assumed to be the same as the first one.","title":"OR"},{"location":"adr/004-add_complex_queries/#and","text":"and can be used if you want to select different criteria for different objects: Query ( Book ) . greater ( 'rating' , 3 ) . and ( Query ( Author ) . equal ( 'id_' , 1 ))","title":"AND"},{"location":"adr/004-add_complex_queries/#join","text":"join can be used to match entities if an entity that is related to them matches one or many condition, for example to get all the books of the author whose id is 1 you can: Query ( Book ) . join ( Query ( Author ) . equal ( 'id_' , 1 ))","title":"Join"},{"location":"adr/004-add_complex_queries/#sorting-the-results","text":"By default the results are sorted by id_ increasingly, to sort by other criteria use the sort method. query . sort ( 'rating' ) To reverse the order of the sorting use the reverse argument: query . sort ( 'rating' , reverse = True ) To order by many criteria chain sort methods, for example if you want to sort by rating and then by created_date you can use: query . sort ( 'rating' ) . sort ( 'created_date' )","title":"Sorting the results"},{"location":"adr/004-add_complex_queries/#number-of-results","text":"By default all results are returned, if you want to receive only a limited amount use the limit method query . limit ( 10 )","title":"Number of results"},{"location":"adr/004-add_complex_queries/#delete-queries","text":"Right now the delete method allows only one or many entities, we can change the signature so that it also allows a Query object that can tweak the delete query instead of just using the id_ .","title":"Delete queries"},{"location":"adr/004-add_complex_queries/#decision","text":"Implement the proposed solution, adding a UserWarning on the old method until we deprecate it.","title":"Decision"},{"location":"adr/004-add_complex_queries/#consequences","text":"Pros: We'll improve a lot the extraction of information from the repo Cons: Users will need to change their code: How they query the repositories.","title":"Consequences"},{"location":"adr/005-simplify_search_and_all_signature/","text":"Status \u00b6 Accepted Context \u00b6 Right now we raise an EntityNotFoundError exception if search returns no results, which forces the user to catch this exception when it makes more sense to return an empty list as these methods are usually used on loops. We're also having some issues with the types of the return values of these methods as we allowed them to be of type Union[Type[Entity], List[Type[Entity]], None] since 003 , both when writing the code as the type hints are difficult to write and debug and also when doing operations on the returned objects, as the returned list contains objects with different models that as they have different attributes and objects they need to be dealt differently. This last point means that the user has to split the results using isinstance at some point. Using that type in get is a bad idea too, as many entities may have the same id_ , and when you get you just want one entity, otherwise you'd use search . The last and first methods are used over the all method not over the search which would be useful too. Proposals \u00b6 Return a list instead of exception \u00b6 search will return an empty list if there are no results instead of an EntityNotFoundError exception. Only allow one model \u00b6 We could revert 003 and only allow one model in search and all but that will mean that the context of that ADR won't be met anymore which was that some applications need to do operations on all or a subset of entity types. They will then be forced to run the desired method once for each entity type which has the next disadvantages: The user has to write more code. Which is not true, as even though you truly have to run repo.search and repo.all more than once, right now you also have to write additional code to tell apart the returned objects. Instead of running everything on a query, many will be done. The potential downside of that is performance loss, but in reality the current implementation is already doing many queries as it's not able to do everything at once. And the next advantages: We've introduced a great deal of complexity on 003 both on functions and type hints, removing them will improve maintainability and peace of mind when coding. Remove conflicts on get . Leave last and first as they are \u00b6 Even though it's true that they could be used on the search result, let's be honest, using [0] and [-1] is not that difficult, and if there are no elements it will return an IndexError a common used exception. As first and last are already coded and it's easy to maintain I'll leave them as they are and assume that search won't have them. Decision \u00b6 Revert the changes of 003 . search will return an empty list if there are no results instead of an EntityNotFoundError exception. Consequences \u00b6 Pros: More maintainable code. Less complexity in the data adapters. Less problems with the type hints. Remove the model conflicts of get Cons: Users will need to update their code as the signature of get , all , search , first , and last will change. The users will have 3 months to do the changes.","title":"Status"},{"location":"adr/005-simplify_search_and_all_signature/#status","text":"Accepted","title":"Status"},{"location":"adr/005-simplify_search_and_all_signature/#context","text":"Right now we raise an EntityNotFoundError exception if search returns no results, which forces the user to catch this exception when it makes more sense to return an empty list as these methods are usually used on loops. We're also having some issues with the types of the return values of these methods as we allowed them to be of type Union[Type[Entity], List[Type[Entity]], None] since 003 , both when writing the code as the type hints are difficult to write and debug and also when doing operations on the returned objects, as the returned list contains objects with different models that as they have different attributes and objects they need to be dealt differently. This last point means that the user has to split the results using isinstance at some point. Using that type in get is a bad idea too, as many entities may have the same id_ , and when you get you just want one entity, otherwise you'd use search . The last and first methods are used over the all method not over the search which would be useful too.","title":"Context"},{"location":"adr/005-simplify_search_and_all_signature/#proposals","text":"","title":"Proposals"},{"location":"adr/005-simplify_search_and_all_signature/#return-a-list-instead-of-exception","text":"search will return an empty list if there are no results instead of an EntityNotFoundError exception.","title":"Return a list instead of exception"},{"location":"adr/005-simplify_search_and_all_signature/#only-allow-one-model","text":"We could revert 003 and only allow one model in search and all but that will mean that the context of that ADR won't be met anymore which was that some applications need to do operations on all or a subset of entity types. They will then be forced to run the desired method once for each entity type which has the next disadvantages: The user has to write more code. Which is not true, as even though you truly have to run repo.search and repo.all more than once, right now you also have to write additional code to tell apart the returned objects. Instead of running everything on a query, many will be done. The potential downside of that is performance loss, but in reality the current implementation is already doing many queries as it's not able to do everything at once. And the next advantages: We've introduced a great deal of complexity on 003 both on functions and type hints, removing them will improve maintainability and peace of mind when coding. Remove conflicts on get .","title":"Only allow one model"},{"location":"adr/005-simplify_search_and_all_signature/#leave-last-and-first-as-they-are","text":"Even though it's true that they could be used on the search result, let's be honest, using [0] and [-1] is not that difficult, and if there are no elements it will return an IndexError a common used exception. As first and last are already coded and it's easy to maintain I'll leave them as they are and assume that search won't have them.","title":"Leave last and first as they are"},{"location":"adr/005-simplify_search_and_all_signature/#decision","text":"Revert the changes of 003 . search will return an empty list if there are no results instead of an EntityNotFoundError exception.","title":"Decision"},{"location":"adr/005-simplify_search_and_all_signature/#consequences","text":"Pros: More maintainable code. Less complexity in the data adapters. Less problems with the type hints. Remove the model conflicts of get Cons: Users will need to update their code as the signature of get , all , search , first , and last will change. The users will have 3 months to do the changes.","title":"Consequences"},{"location":"adr/adr/","text":"ADR are short text documents that captures an important architectural decision made along with its context and consequences. graph TD 001[001: Entity ID definition] 002[002: Support String IDs] 003[003: Make entity_model optional arguments] 004[004: Add complex queries] 005[005: Simplify search and all signature] click 001 \"https://lyz-code.github.io/repository-orm/adr/001-entity_id_definition/\" _blank click 002 \"https://lyz-code.github.io/repository-orm/adr/002-support_string_ids/\" _blank click 003 \"https://lyz-code.github.io/repository-orm/adr/003-make_entity_models_optional_arguments/\" _blank click 004 \"https://lyz-code.github.io/repository-orm/adr/004-add_complex_queries/\" _blank click 005 \"https://lyz-code.github.io/repository-orm/adr/005-simplify_search_and_all_signature/\" _blank 001 -- Partially superseeded --> 002 003 -- Superseeded --> 005 001:::superseeded 002:::accepted 003:::superseeded 004:::draft 005:::accepted classDef draft fill:#CDBFEA; classDef proposed fill:#B1CCE8; classDef accepted fill:#B1E8BA; classDef rejected fill:#E8B1B1; classDef deprecated fill:#E8B1B1; classDef superseeded fill:#E8E5B1;","title":"Architecture Decision Records"}]}